1
00:00:06,971 --> 00:00:10,106
CS231n 두번째 시간에 오신걸 환영합니다.

2
00:00:10,106 --> 00:00:12,646
화요일에 했던 것을 되짚어보자면

3
00:00:12,646 --> 00:00:15,098
컴퓨터비전이 무엇인지,

4
00:00:15,098 --> 00:00:16,187
역사는 어떠했는지,

5
00:00:16,187 --> 00:00:18,101
그리고 이 수업에 대해 다뤘었습니다.

6
00:00:18,101 --> 00:00:21,451
그리고 오늘은 본격적으로 수업을
진행하는 첫 날입니다.

7
00:00:21,451 --> 00:00:23,339
그리고 실생활에서

8
00:00:23,339 --> 00:00:27,864
우리가 배울 알고리즘이 정확히 어떻게
적용되는지를 아주 깊게 살펴 볼 것입니다.

9
00:00:27,864 --> 00:00:31,927
강의의 처음에는 큰 흐름을 다룰 것이고,

10
00:00:31,927 --> 00:00:35,574
그리고 대부분의 수업에서는 좀 더 깊은 
내용을 다룰 것이며

11
00:00:35,574 --> 00:00:39,617
다양한 알고리즘들의 
세부적인 매커니즘에 초점을 맞출 것입니다.

12
00:00:39,617 --> 00:00:43,419
오늘은 이제 첫 학습 알고리즘을 살펴볼 것인데요,
아마 재밌을 것입니다, 제 생각에는요.

13
00:00:43,419 --> 00:00:47,535
일단 진행에 앞서 몇가지 공지사항을 알려드리겠습니다.

14
00:00:47,535 --> 00:00:48,785
첫 번째는 Piazza에 관한 것인데요

15
00:00:49,645 --> 00:00:51,580
어제 확인했을때

16
00:00:51,580 --> 00:00:55,357
Piazza를 가입한 인원이 500명쯤
되었던 것으로 기억합니다.

17
00:00:55,357 --> 00:00:58,493
그리고 그것은 100여명 가량이
아직 가입을 하지 않았다는 것이지요

18
00:00:58,493 --> 00:01:01,457
저는 Piazza가 학생과 조교들의

19
00:01:01,457 --> 00:01:04,221
주요 의사소통 수단이 되었으면 좋겠습니다.

20
00:01:04,221 --> 00:01:07,401
프로젝트 아이디어나, 중간고사, 컨퍼런스와 관련된 질문이

21
00:01:07,401 --> 00:01:12,841
조교들의 메일로 너무 많이 오고 있습니다.

22
00:01:12,841 --> 00:01:16,138
그리고 이런 종류의 질문은 Piazza에서
이루어져야만 합니다.

23
00:01:16,138 --> 00:01:21,568
모든 조교들이 Piazza를  수시로 확인하고 있기 때문에, 
Piazza로 질문을 하는것이 훨씬 더 빠를 것입니다.

24
00:01:21,568 --> 00:01:26,234
이메일로 보내면 여러 메일 리스트랑 섞여서
답장을 못 할 수도 있습니다.

25
00:01:26,234 --> 00:01:28,983
또한 SCPD 학생들 중 일부는

26
00:01:28,983 --> 00:01:33,629
Piazza 가입에 어려움을 겪고 있습니다.

27
00:01:33,629 --> 00:01:37,791
SCPD 학생들은 @ stanford.edu 이메일을
부여 받아야 합니다.

28
00:01:38,804 --> 00:01:40,733
이메일 주소를 부여받으면

29
00:01:40,733 --> 00:01:44,276
그때 Stanford 이메일로 Piazaa에
가입할 수 있습니다.

30
00:01:44,276 --> 00:01:46,908
아마 이 문제는 지금 여기 앉아있는 분들은
상관 없겠지만

31
00:01:46,908 --> 00:01:50,408
SCPD로 듣고있는 학생들에게 말씀드리는 것입니다.

32
00:01:52,191 --> 00:01:55,643
다음 사항은 바로 과제에 관한 것입니다.

33
00:01:55,643 --> 00:01:58,178
과제 1이 오늘 늦게 업로드 될 것입니다.

34
00:01:58,178 --> 00:01:59,517
아마 오후가 될 것 같습니다만

35
00:01:59,517 --> 00:02:03,043
오늘 자기전에는 꼭 과제가 올라갈 것임을
약속드립니다.

36
00:02:03,043 --> 00:02:04,589
하지만 여러분이 조금 불안하고

37
00:02:04,589 --> 00:02:07,304
지금 당장 과제를 하고싶다면

38
00:02:07,304 --> 00:02:10,531
과제 1의 작년버전을 찾을 수 있을 것입니다.

39
00:02:10,531 --> 00:02:12,684
작년 버전도 거의 똑같습니다.

40
00:02:12,684 --> 00:02:15,081
단지 아주 조금만 손 보고 있습니다.

41
00:02:15,081 --> 00:02:19,082
예를 들어 Python 2.7버전에서 
Python3으로 업그레이드하는것 등이죠

42
00:02:19,082 --> 00:02:20,943
그리고 아주 작은 외관의 변화가 있고

43
00:02:20,943 --> 00:02:24,742
내용만 보면 작년과 같습니다.

44
00:02:24,742 --> 00:02:28,665
이번 과제에서 여러분은 여러분만의  k-NN을 
구현하게 될 것인데요

45
00:02:28,665 --> 00:02:30,686
우리가 이번 강의에서 다룰 것입니다.

46
00:02:30,686 --> 00:02:33,514
여러분은 또한 몇가지 선형 분류기를 구현할 것인데

47
00:02:33,514 --> 00:02:35,694
SVM과 Softmas 뿐만 아니라

48
00:02:35,694 --> 00:02:37,927
2-layer 신경망도 구현할 것입니다.

49
00:02:37,927 --> 00:02:42,160
그리고 앞으로 몇 강의동안
그 내용을 모두 다룰 것입니다.

50
00:02:43,112 --> 00:02:46,168
그리고 모든 과제는 Python과 
Numpy를 사용하고 있습니다.

51
00:02:46,168 --> 00:02:49,229
Python이나 Numpy에 익숙하지 않다면

52
00:02:49,229 --> 00:02:51,608
관련한 tutorial이 있으며, 여러분은

53
00:02:51,608 --> 00:02:54,312
우리 강의 사이트에서 찾아 볼 수 있습니다.

54
00:02:54,312 --> 00:02:56,856
그리고 이것은 사실 엄청나게 중요합니다.

55
00:02:56,856 --> 00:02:59,211
NumPy는 여러분들이 vectorized 연산을 아주
효율적으로 할 수 있게 해줄 것이며

56
00:02:59,211 --> 00:03:03,856
방대한 양의 계산은 단지 코드 몇 줄로
가능하도록 해 줄 것입니다.

57
00:03:03,856 --> 00:03:06,081
이건 완전 중요한데, 왜냐하면

58
00:03:06,081 --> 00:03:10,288
대부분의 수치계산, 기계학습과 같은 것들이

59
00:03:10,288 --> 00:03:13,424
vectorized 연산을 수행하기 때문입니다.

60
00:03:13,424 --> 00:03:16,964
그리고 여러분들은 첫 과제를 하면서
많은 연습을 할 수 있을 것입니다.

61
00:03:16,964 --> 00:03:23,449
그러니 Matlab, Numpy와 같은 vectorized 
tensor 계산이 익숙하지 않은 분들은

62
00:03:23,449 --> 00:03:27,606
일찌감치 화제를 시작하기를 추천드립니다.

63
00:03:27,606 --> 00:03:32,175
그리고 tutorial도 아주 주의깊에 읽어보시기 바랍니다.

64
00:03:32,175 --> 00:03:40,198
또 한가지 알려드릴 것은 이 수업에서 쓸
Google Cloud가 공직적으로 지원 된다는 것입니다.

65
00:03:40,198 --> 00:03:43,630
Google Cloud는 Amazon AWS와 유사합니다

66
00:03:43,630 --> 00:03:46,694
여러분은 cloud에서 가상 머신을
사용할 수 있습니다.

67
00:03:46,694 --> 00:03:50,432
이런 가상 머신은 GPU들을 지닐 수 있습니다.

68
00:03:50,432 --> 00:03:55,386
현재 Googld Cloud 사용법과 이것으로 과제를 하는
방법에 관한 Tutorial을 작성중입니다.

69
00:03:55,386 --> 00:04:04,723
여러분들이 이미지만 다운받으면 Google Cloud를 통해
과제를 차질없이 진행할 수 있도록 하기 위함입니다.

70
00:04:04,723 --> 00:04:08,437
그리고 google에서 우리 수업을
아주 잘 지원하고 있기 때문에

71
00:04:08,437 --> 00:04:15,582
Google Cloud Credits을 무료로 쓸 수 있는 쿠폰을
여러분들에게 나누어 줄 수 있을 것입니다.

72
00:04:15,582 --> 00:04:24,015
여러분들은 자유롭게 과제나 프로젝트를 수행할때 필요한
GPU나 고사양 컴퓨터와 같은 자원들을 사용할 수 있습니다.

73
00:04:24,015 --> 00:04:28,023
아마도 오늘  Pizzza에 자세한 사항을
포스팅 하도록 하겠습니다.

74
00:04:28,023 --> 00:04:29,300
여러분들에게 말씀드리고 싶었던 것은 ,

75
00:04:29,300 --> 00:04:35,566
본인의 Laptop을 사용해도 되는지와 같은 여러 질문을 받았습니다만

76
00:04:35,566 --> 00:04:41,774
제 답변은, 여러분은 Google Cloud를 사용할 수 있다는 것이고
이를 위해 쿠폰을 제공받을 것입니다.

77
00:04:43,923 --> 00:04:44,756
자 그럼

78
00:04:45,959 --> 00:04:49,716
지금까지 몇가지 공지사항을
전달해 드렸고,

79
00:04:49,716 --> 00:04:53,681
그런 다음 내용을 자세히 살펴 봅니다.

80
00:04:53,681 --> 00:04:58,125
저번 강의에서 Image Classification에 대해
조금 말씀드렸습니다

81
00:04:58,125 --> 00:05:00,450
이것은 컴퓨터비전의 핵심 과제입니다.

82
00:05:00,450 --> 00:05:04,048
그리고 우리가 가장 가장 초점을 맞출 것입니다.

83
00:05:04,048 --> 00:05:04,964
정확히,

84
00:05:04,964 --> 00:05:07,832
Image Classification을 어떻게 할 수 있을까요?

85
00:05:07,832 --> 00:05:09,750
그래서 좀더 구체적으로,

86
00:05:09,750 --> 00:05:12,142
여러분이 Image Classification을 할때

87
00:05:12,142 --> 00:05:14,259
여러분은 입력 이미지를 받습니다.

88
00:05:14,259 --> 00:05:16,457
여기 예제에 귀여운 고양이가 있습니다.

89
00:05:16,457 --> 00:05:22,455
그리고 시스템은 미리 정해놓은 
카테고리를 알고 있습니다.

90
00:05:22,455 --> 00:05:29,134
그런 카테고리는 개나 고양이 트럭, 비행기 같을 것일 수 있으며

91
00:05:29,134 --> 00:05:34,831
컴퓨터가 할 일은 사진을 보고 
그중 하나를 고르는 것입니다.

92
00:05:34,831 --> 00:05:36,444
이건 엄청 쉬워보입니다.

93
00:05:36,444 --> 00:05:44,346
왜냐면 여러분의 뇌에 있는 시각 체계는 이런 류의 
시간 인식 작업에 고도화 되어 있기 때문입니다.

94
00:05:44,346 --> 00:05:48,232
하지만 기계한테는 정말 어려운 일입니다.

95
00:05:48,232 --> 00:05:53,236
컴퓨터가 이 이미지를 볼때 무엇을 보고 있는지에 대해서
좀만 더 깊게 생각해 본다면

96
00:05:53,236 --> 00:05:57,428
컴퓨터는 우리와는 다르게 고양이 라는 생각을
하지 못 할 것입니다.

97
00:05:57,428 --> 00:06:01,755
컴퓨터는 이미지를 아주 큰 격자 모양의 숫자집합으로
표현하고 있습니다.

98
00:06:01,755 --> 00:06:05,922
800x600 이미지 같이 말입니다.

99
00:06:07,371 --> 00:06:13,176
그리고 각 픽셀은 숫자 세개로 표현되는데 
red, green, blue 값을 의미합니다.

100
00:06:13,176 --> 00:06:15,769
다시 말하자면, 컴퓨터한테 이미지는
단지 거대한 숫자 집합에 불과합니다.

101
00:06:15,769 --> 00:06:24,841
이 숫자 거대한  집합에서 고양이 라는 개념을 끄집어 
내는 것은 정말로 힘듭니다.

102
00:06:26,956 --> 00:06:30,186
그래서 우리는 이걸 의미적론적인 차이라고 부릅니다.

103
00:06:30,186 --> 00:06:32,735
이게 고양이다 라는 생각 혹은 
고양이 라는 레이블은

104
00:06:32,735 --> 00:06:35,462
우리가 이 이미지에 붙힌 의미상의 레이블입니다.

105
00:06:35,462 --> 00:06:42,897
그리고 이 이미지가 "고양이다" 라는 것과 실제 컴퓨터가
보는 픽셀 값과는 아무 큰 차이가 있습니다.

106
00:06:42,897 --> 00:06:45,503
이건 정말 어려운 문제인데 왜냐하면

107
00:06:45,503 --> 00:06:48,901
여러분이 이 사진에 아주 미묘한 변화만 주더라도

108
00:06:48,901 --> 00:06:51,916
저 픽셀 값들은 모조리 다 바뀌게 될 것입니다.

109
00:06:51,916 --> 00:06:54,038
예를들어 저 고양이와 똑같은 고양이를 데리고,

110
00:06:54,038 --> 00:06:55,622
그리고 고양이가 계속 앉아있고,

111
00:06:55,622 --> 00:06:57,352
심지어 조금의 미동도 하지 않는다면

112
00:06:57,352 --> 00:06:58,782
아무 일도 일어나진 않을 것입니다.

113
00:06:58,782 --> 00:07:06,921
하지만 우리가 카메라를 조금만 옆으로 옮긴다면 모든 픽셀
하나 하나가 전부 달라질 것입니다.

114
00:07:06,921 --> 00:07:09,431
하지만 여전히 달라진 픽셀 값도
고양이를 표현하고 있는 것이죠

115
00:07:09,431 --> 00:07:12,754
우리의 알고리즘은 이런 것들에
강인해야 합니다.

116
00:07:12,754 --> 00:07:16,260
바라보는 방향 뿐만 아니라
또다는 문제는 바로 조명입니다.

117
00:07:16,260 --> 00:07:19,298
장면에 따라 서로 다른 조명 조건이 있을 수 있습니다.

118
00:07:19,298 --> 00:07:22,500
고양이가 엄청 어두운 곳에 있던

119
00:07:22,500 --> 00:07:25,520
밝은 곳에 있던, 고양이는 여전히 고양이입니다

120
00:07:25,520 --> 00:07:28,488
우리 알고리즘은 이것에 강인해야 합니다.

121
00:07:28,488 --> 00:07:30,145
객체는 또한 변형될 수 있습니다.

122
00:07:30,145 --> 00:07:34,549
제 생각엔 저기 보이는 것 처럼 
고양이가 제일 많이 변형이 가능한 것 같습니다.

123
00:07:34,549 --> 00:07:38,940
고양이들은 다양한 자세를 취할 수 있습니다.

124
00:07:38,940 --> 00:07:42,441
그리고 우리의 알고리즘은 이런 다양한 종류의
변형에도 강인해야 합니다.

125
00:07:43,442 --> 00:07:45,823
가려짐(occlusion)에서의 문제도 있습니다.

126
00:07:45,823 --> 00:07:49,762
여러분은 고양이의 일부만 볼 수 있을수도 있습니다.
예컨데

127
00:07:49,762 --> 00:07:53,686
고양이의 얼굴 만이라던가, 극단적으로는 소파 쿠션에 숨은
고양이의 꼬리만 볼 수도 있습니다.

128
00:07:53,686 --> 00:07:58,897
사람은 이게 고양이다 라는 것을
아주 쉽게 알 수 있습니다

129
00:07:58,897 --> 00:08:01,532
여전히 이것이 고양이 이미지라는 것을 인식하고 있습니다.

130
00:08:01,532 --> 00:08:08,460
우리의 알고리즘도 이것에 강인해 져야 합니다.
제생각엔 아무 어려운 문제일 것 같긴 하지만요

131
00:08:08,460 --> 00:08:10,792
 background clutter라는 문제도 있습니다.
(배경과 비슷한 경우)

132
00:08:10,792 --> 00:08:16,677
전경 객체인 고양이가 배경과 완전히
비슷하게 생겼을 수도 있습니다.

133
00:08:16,677 --> 00:08:20,389
이것 또한 우리가 처리해야 할 또 다른
과제 중 하나입니다.

134
00:08:20,389 --> 00:08:23,637
또한 클래스 내부에서의 다양성과
관련된 문제도 있습니다.

135
00:08:23,637 --> 00:08:28,455
고양이라는 한 개념이 고양이의 다양한 모습들을 전부 
소화해 내야 합니다.

136
00:08:28,455 --> 00:08:32,158
고양이들은 다양한 외형과 크기, 색, 나이를 지니고 있습니다.

137
00:08:32,158 --> 00:08:36,345
우리의 알고리즘은 그러한 다양한 변화도 
다룰 수 있어야 합니다.

138
00:08:36,345 --> 00:08:40,033
이것 사실 엄청나게 어려운 문제입니다.

139
00:08:40,033 --> 00:08:47,931
우리 뇌는 이런 것들을 아주 잘 해내기 때문에, 컴퓨터에게는 
이 작업이 얼마나 어려울지를 까먹을 수도 있습니다.

140
00:08:47,931 --> 00:08:54,288
그러나 만약 우리가 위에서 언급한 모든 문제를 다룰 수
있는 프로그램을 원한다면, 그리고 단연 고양이 뿐만 아니라

141
00:08:54,288 --> 00:08:59,052
우리가 상상할 수 있는 어떤 객체에 대해서도 다룰 수 있는
프로그램이여야 한다면, 이것은 판타스틱하게 어려운 문제입니다.

142
00:08:59,052 --> 00:09:03,078
저 일은 다 할 수 있다면 아마 기적적일 것입니다. 
제 의견으로는요.

143
00:09:03,078 --> 00:09:04,703
그러나 실제로, 그것은 작동 할뿐만 아니라,

144
00:09:04,703 --> 00:09:09,278
그러나 그런 것들은 약간의 제한된 상황에서는 
인간의 정확도와 유사하게 동작할 수도 있습니다.

145
00:09:09,278 --> 00:09:12,379
수행하는데 수백 ms 밖에 걸리지 않습니다.

146
00:09:12,379 --> 00:09:14,921
이것은 상당히 놀랍고 대단한 기술입니다.

147
00:09:14,921 --> 00:09:22,241
수업의 나머지는 어떤 종류의 진보가 이를 가능하게 
했는지를 살펴 볼 것입니다.

148
00:09:23,492 --> 00:09:27,565
자 그러면, 만약 여러분이 Image 분류기를 위한
API에 대해 고민하고 있다고 해 보자면,

149
00:09:27,565 --> 00:09:31,131
여러분은 아마 이런식의 Python 메서드를
작성 해 보려 할 지 모르겠습니다.

150
00:09:31,131 --> 00:09:34,401
이미지를 입력받고 
어떤 놀라운 마법이 일어난 뒤

151
00:09:34,401 --> 00:09:38,180
그러고 나서는 이 "이미지는 고양이"다, "개다" 라고 말해주는 
클래스 레이블이 튀어 나오는 것입니다.

152
00:09:38,180 --> 00:09:41,695
그리고 이걸 할 수 있는 확실한 묘안이 떠오르진 
않을 것입니다. 그렇죠?

153
00:09:41,695 --> 00:09:43,476
여러분이 알고리즘 수업을 듣고 있고,

154
00:09:43,476 --> 00:09:46,837
여러분이 할 일이 "숫자를 정렬"하거나 
"convex hull을 계산"하거나

155
00:09:46,837 --> 00:09:49,535
또는 "RSA 암호화" 같은 것이었다면

156
00:09:49,535 --> 00:09:55,773
여러분은 알고리즘을 써 내려가면서, 알고리즘이
동작하려면 필요한 모든 과정들을 나열할 것입니다.

157
00:09:55,773 --> 00:10:00,390
그러나 우리가 사물을 인식하려고 할 때,
고양이 또는 이미지를 인식하거나,

158
00:10:00,390 --> 00:10:07,909
객체를 인식하는 데 있어서는 그런 직관적이고 명시적인
알고리즘이 존재하지 않습니다.

159
00:10:07,909 --> 00:10:09,874
그러니 이것은 완전히 어려운 일입니다.

160
00:10:09,874 --> 00:10:13,447
만약 여러분이, 이제 막 첫 과제를 하려고 하고 있고

161
00:10:13,447 --> 00:10:15,464
이 함수를 작성하려고 하고 있을 때

162
00:10:15,464 --> 00:10:18,869
제 생각에는 대부분이 문제에 봉착 할 것입니다.

163
00:10:18,869 --> 00:10:19,740
즉,

164
00:10:19,740 --> 00:10:27,004
확실히, 지금껏 사람들은 서로 다른 동물들을 인식해 내기 위해서 
고오급 coded rules을 만들어내려는 시도를 해 왔습니다.

165
00:10:27,004 --> 00:10:29,193
우리는 마지막 강의에서 이를 조금 다룰것이지만

166
00:10:29,193 --> 00:10:32,095
고양이를 인식하는것에 대한 한 아이디어를 보자면

167
00:10:32,095 --> 00:10:35,596
우리는 고양이가 두 귀가 있고, 입이 있고 코가 있다는 것을
알고 있습니다.

168
00:10:35,596 --> 00:10:37,945
또 우리는 Hubel과 Wiesel의 연구로부터

169
00:10:37,945 --> 00:10:41,641
시각 인식을 할때 edges가 아주 중요하다는 것도 
알 고 있습니다.

170
00:10:41,641 --> 00:10:43,820
그러니 우리가 시도해볼 수 있는 한가지가 있다면

171
00:10:43,820 --> 00:10:45,425
이미지의 edges를 계산하는 것입니다.

172
00:10:45,425 --> 00:10:50,983
그리고는 여러 코너와 경계선의 카테고리를 분류합니다.

173
00:10:50,983 --> 00:10:53,146
만약 세개의 선이 이런 식으로 만나면 이건 코너고,

174
00:10:53,146 --> 00:10:55,186
귀는 "여기에 코너 하나" "저기에 코너 하나"

175
00:10:55,186 --> 00:10:56,483
또 "저기에도 코나 하나" 가 있고

176
00:10:56,483 --> 00:11:01,608
이런 식으로, 고양이를 인식하기 위해서 
이런 식으로 "명시적인 규칙 집합" 을 써 내려 가는 것입니다.

177
00:11:01,608 --> 00:11:04,391
아지만 이런 방식은 잘 동작하지 않는 다는 것이 밝혀졌습니다.

178
00:11:04,391 --> 00:11:06,127
한가지 이유는, 이런 알고리즘은
강인하지 못하다는 것이고

179
00:11:06,127 --> 00:11:15,005
두번째는, 우리가 또 다른 객체를 가지고 한다 치면, 고양이는 신경쓰지
않은채로 트럭에 대해서, 개에 대해서 만들게 될 것입니다.

180
00:11:15,005 --> 00:11:17,081
그러면 이 모든걸 다시 시작해야 합니다.

181
00:11:17,081 --> 00:11:19,853
즉, 이런 방법은 전혀 확장성있는 방법이 아닙니다.

182
00:11:19,853 --> 00:11:25,181
우리는 이 세상에 존재하는 다양한 객체들에게 유연하게
적용될 수 있는

183
00:11:25,181 --> 00:11:29,360
확장성 있는 알고리즘이나 방법을 만들고 싶었습니다.

184
00:11:31,311 --> 00:11:34,766
이런 일을 가능할 수 있게 만든 한 통찰은 바로

185
00:11:34,766 --> 00:11:38,092
데이터 중심 접근 방식에 대한 아이디어입니다.

186
00:11:38,092 --> 00:11:45,766
고양이는 무엇이다, 물고기는 무엇이다 하면서 손으로 
직접 어떤 규칙을 써내려 하는 것 대신에

187
00:11:45,766 --> 00:11:47,845
우리는 인터넷으로 가서

188
00:11:47,845 --> 00:11:55,402
엄청 많은 고양이 데이터, 엄청 많은 비행기 데이터, 엄청 많은
사슴 데이터를 포함한 방대한 데이터 셋을 수집하였습니다.

189
00:11:55,402 --> 00:11:59,138
그리고 우리는 다양한 카테고리들의 방대한 데이터들을 모으기 위해

190
00:11:59,138 --> 00:12:03,866
Google Image Search와 같은 도구들을 이용할 수 있었습니다.

191
00:12:03,866 --> 00:12:08,338
사실 그렇게 방대한 량의 데이터를 모으는 것은 엄청나게
많은 노력이 필요합니다.

192
00:12:08,338 --> 00:12:14,105
다행이도 우리가 사용할 수 있는 고퀄의 데이터셋들이 존재합니다.

193
00:12:14,105 --> 00:12:16,073
우리가 데이터셋을 얻고 나면

194
00:12:16,073 --> 00:12:20,869
우리는 그 모든 데이터를 집어 삼킬 기계학습 분류기를
학습시킵니다.

195
00:12:20,869 --> 00:12:28,446
그럼 알고리즘은 어떤 식으로든 데이터를 요약해서는 서로 다른 객체들을
인식할 수 있는 어떤 모델을 뱉어냅니다.

196
00:12:28,446 --> 00:12:31,756
그리고 최종적으로 이 학습 모델을 새로운 이미지에 
적용시키게 되면

197
00:12:31,756 --> 00:12:35,930
이 모델은 고양이나 개를 인식해 낼 수 있을 것입니다.

198
00:12:35,930 --> 00:12:38,428
이 부분에서 API 가 조금 변경되었습니다.

199
00:12:38,428 --> 00:12:42,099
이미지를 입력하면 고양이를 인식하는 단일 함수가 있는 것 대신에

200
00:12:42,099 --> 00:12:43,621
우리는 이제 함수가 두 개 있는 것입니다.

201
00:12:43,621 --> 00:12:49,115
하나는 학습을 위한 것이고, 이미지와
레이블을 입력으로 주면 모델을 출력합니다.

202
00:12:49,115 --> 00:12:52,030
그리고 별도적으로 또 하나의 함수는
예측 함수인데

203
00:12:52,030 --> 00:12:55,276
모델을 입력하면 이미지를 예측해 주는 것입니다.

204
00:12:55,276 --> 00:12:56,780
이것은 key insight입니다.

205
00:12:56,780 --> 00:13:01,928
이 key insight은 지난 10-20년간  
모든 것이 실제로 잘 동작하게 해 줬습니다.

206
00:13:05,784 --> 00:13:11,111
이 수업은 주로 신경망, CNN, 딥러닝 과 같은 것들을
다룹니다.

207
00:13:11,111 --> 00:13:15,819
하지만 데이터 중심이라는 아이디어는 단지 딥러닝에서
뿐만 아니라 좀 더 일반적으로 퍼져있던 개념입니다.

208
00:13:15,819 --> 00:13:19,145
제생각에는 좀 더 복잡하고 어려운 것을 하기 전에

209
00:13:19,145 --> 00:13:23,058
엄청 간단한 분류기를 한번 다뤄보고 가는것이
좋을 것 같습니다.

210
00:13:23,058 --> 00:13:28,907
아마도 여러분이 상상할 수 있는 가장 단순한 분류기가
있는데 우리는 이것을 nearest neighbor라고 부릅니다.

211
00:13:28,907 --> 00:13:31,243
알고리즘은 솔직히 너무 단순하긴 합니다.

212
00:13:31,243 --> 00:13:34,315
그래서 학습 스텝에서 우리는
아무 일도 하지 않을 것입니다.

213
00:13:34,315 --> 00:13:39,108
단지 모든 학습 데이터를 기억할 뿐입니다.
엄청 쉽습니다

214
00:13:39,108 --> 00:13:43,191
예측 스텝에서는
새로운 이미지가 주어지면

215
00:13:43,191 --> 00:13:47,964
새로운 이미지와 학습 데이터의 유사성을 비교해서

216
00:13:47,964 --> 00:13:51,453
가장 유사한 이미지로 레이블링을 예측하는 것입니다.

217
00:13:51,453 --> 00:13:53,169
아주 간단한 알고리즘 입니다.

218
00:13:53,169 --> 00:13:58,771
하지만 데이터 중심 방법론이라는 관점에서는
좋은 점들이 많다고 볼 수 있습니다.

219
00:13:59,977 --> 00:14:01,680
좀 더 구체적으로 들어가 보자면

220
00:14:01,680 --> 00:14:04,951
여러분들은 CIFAR-10 데이터셋을 다루게 될 것입니다.

221
00:14:04,951 --> 00:14:09,259
이 데이터셋은 기계학습 분야에서 아주 널리 쓰이며
일종의 작은 테스트용 데이터셋입니다.

222
00:14:09,259 --> 00:14:11,579
그리고 여러분들은 과제에서 이 데이터셋을 
다루게 될 것입니다.

223
00:14:11,579 --> 00:14:15,159
CIFAR-10 데이터 셋은 
10 가지 클래스를 제공합니다.

224
00:14:15,159 --> 00:14:19,920
비행기와 자동차, 새와 고양이 등이 있습니다.

225
00:14:19,920 --> 00:14:24,990
10개의 각 카테고리가 있고
50,000여개의 학습 이미지를 제공합니다.

226
00:14:27,173 --> 00:14:30,250
50,000개의 데이터가 각 카테고리에 
균등하게 분포하고 있습니다.

227
00:14:30,250 --> 00:14:37,565
그리고 여러분들이 알고리즘을 테스트하는데 사용하게될
10,000여개의 테스트 이미지가 있습니다.

228
00:14:38,707 --> 00:14:45,741
그러면 이 CIFAR-10 테스트 이미지에 
간단한 NN 예제를 적용 해 보겠습니다.

229
00:14:45,741 --> 00:14:53,693
오른쪽 칸의 제일 왼쪽 줄은
CIFAR-10의 테스트 이미지입니다.

230
00:14:53,693 --> 00:14:58,375
그리고 그 오른쪽 이미지들은 
학습 이미지를 분류하고

231
00:14:58,375 --> 00:15:03,571
각각의 테스트 예제와 가장 유사한 학습 이미지를
보여줍니다.

232
00:15:03,571 --> 00:15:07,938
테스트 이미지들이 학습 이미지와 비교했을때
눈으로 보기에는 꽤 비슷하게 생겼습니다.

233
00:15:07,938 --> 00:15:10,974
뭐 항상 맞는것은 아니지만 말입니다. 그렇죠?

234
00:15:10,974 --> 00:15:14,687
두번째 행을 보면, 사실 이게 좀 보기 힘듭니다

235
00:15:14,687 --> 00:15:21,224
이미지들이 32 x 32 픽셀로 되어 있기 때문에 
좀 더 유심히 보고 짐작해 보시기 바랍니다.

236
00:15:21,224 --> 00:15:23,850
어찌됐든, 두번째 행의 이미지는 개 입니다.
바로 옆에 있는 NN도 개 입니다.

237
00:15:23,850 --> 00:15:30,006
하지만 그 다음에 있는건 "사슴"이나 "말"같이 보이는군요

238
00:15:30,006 --> 00:15:33,237
하지만 여러분들은 얘네가 눈으로 보기에는
아주 유사해 보인다는 것을 알 수 있습니다.

239
00:15:33,237 --> 00:15:36,370
중간에 흰색 뭉텅이가 있거나 하는 식으로 보면 말이죠

240
00:15:36,370 --> 00:15:39,651
그래서 우리가 이 이미지에 NN 알고리즘을 적용한다면,

241
00:15:39,651 --> 00:15:42,707
우리는 트레이닝 셋에서 "가장 가까운 샘플"을 찾게 될 것입니다.

242
00:15:42,707 --> 00:15:47,135
우리는 그렇게 찾은 "가장 가까운 샘플"의 레이블을 알 수 
있습니다. 이 샘플들은 학습 데이터에서 나온 것이기 때문입니다

243
00:15:47,135 --> 00:15:50,875
그래서 우리는 이 테스트 이미지 또한 "개"이다 라는 것을
쉽게 알 수 있을 것입니다.

244
00:15:50,875 --> 00:15:55,851
여러분들이 이 예제가 엄청 잘 동작하지 않을것 
같다고 생각하실 수도 있지만

245
00:15:55,851 --> 00:16:00,018
그럼에도 이 예제는 해볼만한 아주 좋은 예제입니다.

246
00:16:00,939 --> 00:16:03,724
하지만 한가지 알아야 할 것은

247
00:16:03,724 --> 00:16:06,908
이미지 쌍이 주어졌을때
어떻게 그것들을 비교할지에 관한 것입니다.

248
00:16:06,908 --> 00:16:10,573
왜냐면 우리가 테스트 이미지를 하나 고르고 
이것을 모든 학습 이미지들과 비교한다 했을때

249
00:16:10,573 --> 00:16:12,165
사실 여러가지 방법이 있을 수 있습니다.

250
00:16:12,165 --> 00:16:15,640
정확히는, 비교 함수가 어떻게 생겼는지에 달렸습니다.

251
00:16:15,640 --> 00:16:20,008
이전 슬라이드의 예제에서는
L1 Distance라는 것을 사용했습니다.

252
00:16:20,008 --> 00:16:22,547
Manhattan distance 라고도 하지요

253
00:16:22,547 --> 00:16:27,448
이미지들을 비교할 때 이 방법은 아주 쉽고
단준한 방법입니다.

254
00:16:27,448 --> 00:16:32,969
이미지간의 각각의 개별적인 픽셀 하나 하나를 
비교하는 것입니다.

255
00:16:32,969 --> 00:16:39,346
테스트 이미지가 4x4 이미지라고 생각해보면

256
00:16:39,346 --> 00:16:43,172
그러고 테스트 이미지의 픽셀 하나를

257
00:16:43,172 --> 00:16:46,242
같은 자리의 트레이닝 이미지의 픽셀로 뺴줍니다. 
그리고 그 값의 절댓값을 취합니다

258
00:16:46,242 --> 00:16:49,068
그러면 두 이미지간의 픽셀의 차이 값을 
계산한 것입니다.

259
00:16:49,068 --> 00:16:51,950
그리고 이미지 내 모든 픽셀의 수행 결과를 모두 더합니다.

260
00:16:51,950 --> 00:16:54,213
이런 방식으로 이미지를 분류하는 것은
어리석은 일이지만

261
00:16:54,213 --> 00:16:57,963
하지만 여전히 생각해볼 만한 것들도 있습니다.

262
00:16:57,963 --> 00:17:01,991
이 방법은 두 이미지의 차이를 측정할 수 있는
아주 구체적인 방법을 제시합니다.

263
00:17:01,991 --> 00:17:07,147
이 예제의 경우에는 두 이미지간에
456이라는 차이가 있습니다.

264
00:17:08,446 --> 00:17:13,233
NN 분류기를 구현한 전체 Python 코드가 있습니다.

265
00:17:13,233 --> 00:17:16,582
상당히 짧고 간결하다는 것을 알 수 있습니다.

266
00:17:16,583 --> 00:17:21,348
NumPy에서 제공하는 Vectorizaed 연산을
이용했기 떄문입니다.

267
00:17:21,348 --> 00:17:26,247
여기에서는 우리가 얼마전에 얘기했던 
학습과 관련된 함수를 볼 수 있는데

268
00:17:26,247 --> 00:17:28,946
NN의 경우 아주 단순하죠

269
00:17:28,946 --> 00:17:33,427
단지 학습 데이터를 기억하는 것입니다.
크게 할 일이 딱히 없습니다

270
00:17:33,427 --> 00:17:39,126
이제 테스트 함수에서는 이미지를 입력으로 받고
이를 L1 Distance를 이용해서 비교합니다

271
00:17:39,126 --> 00:17:45,395
학습 데이터와 테스트 이미지를 가지고 비교를 해서 
트레이닝 셋에서 가장 유사한 것들을 찾아냅니다.

272
00:17:45,395 --> 00:17:50,113
그리고 그 일은 Python code 한 두 줄이면 충분합니다.

273
00:17:50,113 --> 00:17:53,882
Numpy의 vectorized 연산을 이용해서 말이죠

274
00:17:53,882 --> 00:17:57,779
여러분들은 첫 과제에서 이 것들을
연습하게 될 것입니다.

275
00:17:58,628 --> 00:18:02,179
그러면, 이 간단한 분류기에 대해서 
몇가지 물음이 있을 수 있겠습니다.

276
00:18:02,179 --> 00:18:04,910
첫째, 우리의 트레이닝 셋에 N개의 이미지가 들어있다면

277
00:18:04,910 --> 00:18:09,077
트레이닝, 테스트 속도가 얼마나 될까 하는 것입니다

278
00:18:12,233 --> 00:18:17,878
딱히 일이 없는 트레이닝쪽은 속도는 상수시간 일 것입니다.
단지 데이터를 기억하고 있는 것이죠. O(1)

279
00:18:17,878 --> 00:18:22,703
pointer를 사용해서 복사한다면, 데이터가 얼마나 크던
상수시간으로 끝날 수 있을 것입니다.

280
00:18:22,703 --> 00:18:31,099
하지만 테스트를 할때는 N개의 모든 학습용 데이터를 
테스트 이미지와 비교해야만 합니다.

281
00:18:31,099 --> 00:18:33,766
그리고 이 일은 실제로 너무 느립니다.

282
00:18:34,991 --> 00:18:38,641
하지만 생각해보면 이건 완전 "거꾸로" 된 것입니다.
(Train TIme < Test  TIme)

283
00:18:38,641 --> 00:18:45,326
실용적인 측명으로 보면 우리는 "학습 시간이 느리고"
"테스트 시간은 빠르길" 원합니다

284
00:18:45,326 --> 00:18:49,882
왜냐하면, 여러분이 데이터 센터같은 곳에서 어떤 분류기를
학습시키고 있다고 생각해보면

285
00:18:49,882 --> 00:18:54,640
좋은 성능의 분류기를 만들기 위해서 "학습"하는데
많은 시간을 들일 수 있을 것입니다.

286
00:18:54,640 --> 00:18:57,566
하지만 여러분이 이 분류기를 
"테스트"하려 한다고 생각해보면

287
00:18:57,566 --> 00:19:02,248
여러분이 그것을 핸드폰이나, 브라우저와 같은
low power device에서 돌려보고 싶을 수 있고

288
00:19:02,248 --> 00:19:07,075
여러분은 여러분의 분류기가 어느정도 빠른 성능을
보이길 원할 것입니다.

289
00:19:07,075 --> 00:19:11,826
그런 관점에서 보면 NN 알고리즘은 사실
거꾸로 된 경우인 것입니다.

290
00:19:11,826 --> 00:19:16,420
그리고 CNN이나 그런 부류의 parametic 모델을
생각해보면

291
00:19:16,420 --> 00:19:18,286
NN과 정 반대하는 것을 알 수 있습니다.

292
00:19:18,286 --> 00:19:24,936
학습 시간은 오래 걸리겠지만 
테스트 시간을 완전 빠를 것입니다.

293
00:19:24,936 --> 00:19:30,816
 NN알고리즘을 우리가 실제로 적용했을 때 정확히
어떤식으로 보일지에 대한 물음이 남아있습니다.

294
00:19:30,816 --> 00:19:36,130
여기에 우리가 NN의 decision regions 이라는 것을
그려 보았습니다.

295
00:19:36,130 --> 00:19:42,021
여기 2차원 평면에 이 점들은
학습 데이터들 입니다.

296
00:19:42,021 --> 00:19:47,547
그리고 점의 색은 그 점의 카테고리, 즉 클래스 레이블을 나타냅니다.

297
00:19:47,547 --> 00:19:49,221
여기에는 5개의 클래스가 있다는 것을 알수 있습니다.

298
00:19:49,221 --> 00:19:51,543
저 위 구석에는 파란색이 있고

299
00:19:51,543 --> 00:19:53,921
오른쪽 위에는 보라색이 있고

300
00:19:53,921 --> 00:19:56,491
그리고 이제 전체 평면의 모든 픽셀에 대해서

301
00:19:56,491 --> 00:20:02,560
각 픽셀이 어떤 학습 데이터와 가장 가까운지를 계산했습니다.

302
00:20:02,560 --> 00:20:06,954
그런 다음 해당 클래스 레이블에 해당하는 색으로 칠했습니다.

303
00:20:06,954 --> 00:20:11,032
이는 NN 분류기를 일종의 공간을 분할하는 작업을 수행하고

304
00:20:11,032 --> 00:20:14,979
해당하는 색을 칙하는 것으로 볼 수 있습니다.

305
00:20:14,979 --> 00:20:18,320
하지만 이 분류기는 엄청 좋다고는 할 수 없습니다.

306
00:20:18,320 --> 00:20:24,676
이 그림을 보면서 우리는 이 NN 분류기에서 발생할지
모르는 문제들에 대해서 살펴볼 수 있습니다.

307
00:20:24,676 --> 00:20:31,591
하나 들자면, 가운데에는 대부분이 초록점인데
중간에 노란 점 하나가 있습니다.

308
00:20:31,591 --> 00:20:38,552
하지만 우리는 단지 "가장 가까운 이웃" 만을 보기 때문에 이는 
녹색의 무리 한개운데 "노란색 섬" 을 나타나게 합니다.

309
00:20:38,552 --> 00:20:40,087
아마 이것은 좋은 일은 아닐 것입니다.

310
00:20:40,087 --> 00:20:44,081
아마 그런 점들도 초록색이어야 할 것입니다.

311
00:20:44,081 --> 00:20:50,225
그리고 비슷하게 파란색 지역을 침범하고 있는
"손가락 모양의 초록색 지역"또한 볼 수 있는데

312
00:20:50,225 --> 00:20:55,180
이것은 한 점이 그곳에 있어서 그런데,
아마 이 점은 잡음(noise)이거나 가짜(spurious)일 것입니다.

313
00:20:55,180 --> 00:21:01,606
이런 것들은, NN의 조금 더 일반화된 버전인
k-NN 알고리즘이 만들어진 동기가 되었습니다.

314
00:21:01,606 --> 00:21:05,070
단순하기 하나의 가장 가까운 이웃을 탐색하기 보다는

315
00:21:05,070 --> 00:21:08,021
대신에 우리는 좀더 멋있는 것을 할 것입니다.

316
00:21:08,021 --> 00:21:10,627
일종의 distance metric을 이용해서 
K개의 가까운 이웃을 찾는 것입니다.

317
00:21:10,627 --> 00:21:15,057
그리고 여러 이웃들끼리 투표를 하는 것입니다.

318
00:21:15,057 --> 00:21:18,733
그리고 여러 이웃들 중 가장 많은 득표수를 가진 것으로
예측하는 것입니다.

319
00:21:18,733 --> 00:21:21,032
아마 여러분은 이를 위해서는 약간은 더 복잡한 방법이 
필요할 것이라고 생각해 볼 수 있을 것입니다.

320
00:21:21,032 --> 00:21:24,148
거리별로 가중치를 가지고 투표를 한다던가 
하는 것들이 있겠지요

321
00:21:24,148 --> 00:21:27,912
하지만 가장 잘 동작하는 제일 쉬운 방법은

322
00:21:27,912 --> 00:21:29,810
그저 가장 많은 득표수를 취하는 것입니다.

323
00:21:29,810 --> 00:21:35,899
정확히 같은 데이터를 사용한 k-nn 분류기들이 있습니다.

324
00:21:35,899 --> 00:21:39,928
K=1 일때가 있고, 중앙과 오른쪽에는  K=3일떄
K = 5 일때가 있습니다.

325
00:21:39,928 --> 00:21:43,792
K=3 일때는 살보자면

326
00:21:43,792 --> 00:21:50,966
이전에 초록색 무리 중안에 자리잡고있었던 노란색 점이 더 이상 노란 지역을
만들어내지 않는다는 것을 알 수 있습니다.

327
00:21:50,966 --> 00:21:55,852
이제는 중앙의 초록색 부분은 완전하게
초록색으로 분류되고 있습니다.

328
00:21:55,852 --> 00:21:59,272
그리고 빨간색과 파란색 영역 사이의 손가락들이

329
00:21:59,272 --> 00:22:00,823
점점 부드러워지기 시작했습니다.

330
00:22:00,823 --> 00:22:02,454
다수결로 인한 것이죠.

331
00:22:02,454 --> 00:22:05,381
K=5의 경우를 보자면

332
00:22:05,381 --> 00:22:08,437
파란색과 빨간색 영역 사이의 결정경계가

333
00:22:08,437 --> 00:22:12,064
아주 부드럽고 훌륭하게 만들어 졌습니다.

334
00:22:12,064 --> 00:22:14,727
대게 여러분이 NN분류기를 사용하게 된다면

335
00:22:14,727 --> 00:22:20,771
여러분들은 대게 1보다는 큰 값의 K를 사용하고 싶을 것입니다.

336
00:22:20,771 --> 00:22:26,064
왜냐하면 K가 1보다 큰 것이 결정 경계를 더 부드럽게 하고 
더 좋은 결과를 이끌어 주기 때문입니다.

337
00:22:29,252 --> 00:22:30,159
질문있나요?

338
00:22:30,159 --> 00:22:34,279
[질문하는 학생]

339
00:22:34,279 --> 00:22:35,208
알겠습니다. 질문은

340
00:22:35,208 --> 00:22:38,133
"흰색 지역은 어떻게 처리하나요?" 인데요

341
00:22:38,133 --> 00:22:43,247
흰색 영역은 k-nn에서 "대다수"를 결정할 수 없는 지역입니다.

342
00:22:43,247 --> 00:22:45,521
여러분들은 조금 더 좋은 방법을 생각할 수 있을 것입니다.

343
00:22:45,521 --> 00:22:50,472
어떤 식으로든 추론을 해보거나 임의로 정할 수도 있겠지요

344
00:22:50,472 --> 00:22:55,668
하지만 여기 단순한 예제에서는 이 곳에서는 가장 가까운 이웃이 
존재하지 않음을 나타내기 위해서 흰색으로 칠했습니다.

345
00:23:00,005 --> 00:23:02,439
우리가 컴퓨터비전에 대해 생각하는데 있어서

346
00:23:02,439 --> 00:23:06,616
다양한 관점을 유연하게 다루는 능력이 매우 유용하다고 생각합니다.

347
00:23:06,616 --> 00:23:09,480
하나는 고차원 공간에 존재하는 점들 이라는 측면이고

348
00:23:09,480 --> 00:23:13,049
다른 하나는 그저 실제 이미지로 보는 것입니다.

349
00:23:13,049 --> 00:23:19,048
왜냐하면 이미지의 픽셀들은 이미지를 고차원 벡터로 
여길 수 있게 해주기 때문입니다.

350
00:23:19,048 --> 00:23:23,395
이런 두가지 측면을 왔다 갔다 할 수 있는 것은 매우 유용합니다.

351
00:23:23,395 --> 00:23:27,876
다시 k-nn을 가지고 이미지로 돌아가 보자면

352
00:23:27,876 --> 00:23:29,443
여러분들은 k-nn이 별로 안좋다는 것을 알 수 있습니다.

353
00:23:29,443 --> 00:23:35,385
제가 여기에 잘 분류되었는지 
아닌지를 초록색과 빨간색으로 표시해 놨습니다.

354
00:23:35,385 --> 00:23:38,288
그리고 정말 안좋아 보입니다.

355
00:23:38,288 --> 00:23:41,459
하지만 더 큰 K값을 사용한다면

356
00:23:41,459 --> 00:23:47,264
투표를 하는데 제일 유사한 하나만 쓰는것이 아니라
상위 세개, 혹은 다섯개, 심지어는 행 전체를 이용할 수도 있을 것입니다.

357
00:23:47,264 --> 00:23:55,325
더 많은 이웃을 고려하면서 이웃들을 검색하게 되면 
여러 잡음에 더 강인해 질 것임을 상상해 볼 수 있습니다.

358
00:23:57,070 --> 00:24:01,666
우리가 k-nn 알고리즘에서 결정해야할 다른 한가지가 있습니다.

359
00:24:01,666 --> 00:24:05,727
그것은 바로 서로 다른 점들을 어떤 방식으로 비교해야 하는지 입니다.

360
00:24:05,727 --> 00:24:11,666
지금까지는 L1 Distance만을 예제로 봐 왔습니다.

361
00:24:11,666 --> 00:24:15,126
이는 픽셀간의 차이의 절대값의 합을 이용하는 것입니다.

362
00:24:15,126 --> 00:24:18,299
하지만 또다른 선택지중 하나는 바로 
L2, 즉 Euclidean distance인데

363
00:24:18,299 --> 00:24:24,491
제곱들의 합의 제곱근을 거리로 이용하는 것입니다.

364
00:24:24,491 --> 00:24:28,727
다른 거리 측정 기준을 고르는 것은 아주 흥미로운 주제입니다.

365
00:24:28,727 --> 00:24:30,072
왜냐하면 서로 다른 거리측정 기준은

366
00:24:30,072 --> 00:24:35,386
그 공간에서 기대할 수 있는 근본적인 기하학적 구조에
대한 새로운 가정을 세우기 떄문입니다.

367
00:24:35,386 --> 00:24:41,688
왼쪽에 보이는 L1 Distance는 사실 L1 Distance의
입장에서는 원입니다. (모양은 사각형)

368
00:24:41,688 --> 00:24:45,020
그리고 원점을 기준으로 하는 사각형의 모양입니다.

369
00:24:45,020 --> 00:24:47,637
각 점들은 이 사각형 위에 존재하며

370
00:24:47,637 --> 00:24:51,017
L1에 따르면 이 점들은 모두 같은 거리에 존재하는 것입니다. 
(L1의 입장에서는 모두 같은 거리에 있는 점들의 집합이니 원임)

371
00:24:51,017 --> 00:24:53,116
반면 L2, Euclidean distance의 경우에는

372
00:24:53,116 --> 00:24:55,290
이 원이 바로 우리에게 익숙한 원이죠

373
00:24:55,290 --> 00:24:57,241
L2의 모양은 우리가 예상한 그대로 입니다.

374
00:24:57,241 --> 00:25:00,798
이 두 metrics간에 아주 흥미로운 차이가 있는데

375
00:25:00,798 --> 00:25:05,135
L1 Distance는 여러분의 좌표 시스템의 선택에 
영향을 받는다는 것입니다.

376
00:25:05,135 --> 00:25:07,306
그러니까, 여러분이 좌표계를 회전시키거나 하면

377
00:25:07,306 --> 00:25:10,201
점들 간의 L1 distance가 바뀌게 되는 것입니다.

378
00:25:10,201 --> 00:25:18,281
반면 L2 Distance의 경우에는 어떤 좌표계와 아무 상관이 없습니다.

379
00:25:18,281 --> 00:25:24,791
만약 입력된 특징벡터 안의 각각 요소들이 어떤 중요한
의미를 가지고 있다면

380
00:25:24,791 --> 00:25:27,935
L1 Distance가 더 잘 맞을 수도 있을지 모릅니다.

381
00:25:27,935 --> 00:25:30,533
그러나 그것이 어떤 공간에서의 일반적인 벡터 일 경우에는

382
00:25:30,533 --> 00:25:34,121
그리고 우리가 그 벡터 요소들간에 어떤 실질적인 의미가
있는지를 잘 알지 못한다면

383
00:25:34,121 --> 00:25:37,531
아마도 L2 Distance가 조금은 더 잘 맞을 수 있습니다.

384
00:25:37,531 --> 00:25:41,839
서로 다른 거리 척도를 사용하는 것에 대해서
또다른 주목할 점은 바로

385
00:25:41,839 --> 00:25:46,343
우리는 다양한 많은 타입의 데이터를 K-NN 분류기를 통해
일반화 시킬 수 있습니다.

386
00:25:46,343 --> 00:25:48,280
단지 벡터나 이미지에서 뿐만이 아닌 것입니다.

387
00:25:48,280 --> 00:25:51,410
에를 들어 여러분이 어떤 문장을 분류하는 일이 있다고 생각해 보면

388
00:25:51,410 --> 00:25:55,366
우리가 k-nn 분류기를 이 문제에 사용하기 위해 해야할 일은 그저

389
00:25:55,366 --> 00:25:57,716
어떤 거리 척도를 사용할지를 정하는 것입니다.

390
00:25:57,716 --> 00:26:03,831
그 척도가 될 수 있는것은 두 문장간의 거리를 측정할 수 
있는 어떤것이든 가능합니다.

391
00:26:03,831 --> 00:26:12,701
어떤 거리 척도를 사용할지를 정하는 것 만으로 우리는 
이 알고리즘은 어떤 종류의 데이터에도 일반적으로 적용할 수 있습니다.

392
00:26:12,701 --> 00:26:20,283
비록 이 알고리즘이 단순하긴 하지만 어떤 새로운 문제를
접하고 있을때 시도해볼만한 좋은 수단이 될 수 있는 것입니다.

393
00:26:21,805 --> 00:26:28,441
자 그러면 다양한 거리 측정 기준을 선택함으로써 
실제 기하학적으로 어떤 변화가 일어나는지 생각해 봅시다.

394
00:26:28,441 --> 00:26:33,577
여기 같은 데이터를 가지고 비교한 두개의 모델이 있는데

395
00:26:33,577 --> 00:26:38,087
왼쪽에는 L1 Distance를 사용했고, 오른쪽은 L2 Distance를
사용한 것입니다.

396
00:26:38,087 --> 00:26:44,093
그리고 두 개의 척도 사이에 실제 결정 경계의 모양이
서로 다름을 알 수 있습니다.

397
00:26:44,093 --> 00:26:49,337
왼쪽의 L1 Distance를 보자면 이는 결정 경계가 
좌표 축의 영향을 받는 경향이 있음을 알 수 있습니다.

398
00:26:49,337 --> 00:26:53,451
다시 말하지만, L1 Distance는 우리가 좌표 시스템을
어떻게 선택하는지에 영향을 받기 때문입니다.

399
00:26:53,451 --> 00:27:00,294
반명 L2 Distance는 촤표축을 신경쓰지 않고 결정 경계를 
만들기 때문에 좀 더 자연스러워 보입니다.

400
00:27:04,161 --> 00:27:08,669
사실 지금까지 보여드린 모든 예제는

401
00:27:08,669 --> 00:27:14,618
제가 만든 웹 데모사이트에서 가져온 것입니다. 여기에서는
여러분만의 k-nn 분류기를 만들어 볼 수 있습니다.

402
00:27:14,618 --> 00:27:17,938
이 프로텍터 스크린으로 보여드리기가 참 어렵군요

403
00:27:17,938 --> 00:27:21,271
집에가서 한번 해보시기 바랍니다.

404
00:27:26,820 --> 00:27:29,403
다시 돌아가 봅시다

405
00:27:32,951 --> 00:27:35,784


406
00:28:07,103 --> 00:28:09,679
좋습니다 말썽이 좀 있었습니다

407
00:28:09,679 --> 00:28:13,496
여기에서는 웹 데모를 건너 뛸 것이지만 
여러분의 컴퓨터로 한번 꼭 해보시기 바랍니다.

408
00:28:13,496 --> 00:28:26,029
실제로는 상당히 재밌고 K 값이나 거리 척도가 바뀜에 따라서 어떻게 
결정 경계가 만들어지는지에 대한 직관을 얻을 수 있습니다.

409
00:28:30,641 --> 00:28:34,072
좋습니다. 그러면 여기에서의 질문은 바로 
우리가 실제로 알고리즘을 사용하려고 할때

410
00:28:34,072 --> 00:28:37,178
우리가 선택해야만 하는 몇가지 항목이 있다는 것입니다.

411
00:28:37,178 --> 00:28:39,426
이전에 다양한 K값의 대해서 이야기했습니다.

412
00:28:39,426 --> 00:28:41,520
L1/L2와 같은 거리의 척도에 관해서도 이야기 했습니다.

413
00:28:41,520 --> 00:28:47,286
그리고 그 질문은 "어떻게 우리의 문제나 데이터에 맞는 
그런 결정을 할 수 있는지" 가 됩니다.

414
00:28:47,286 --> 00:28:53,937
K나 거리척도와 긑은 것들을 우리는 
"하이퍼 파라미터" 라고 부릅니다.

415
00:28:53,937 --> 00:28:57,289
하이퍼 파라미터는 트레이닝 데이터로부터 학슴할 수 있는
것이 아니기 떄문에

416
00:28:57,289 --> 00:29:01,313
대신 여러분이 학습하기 전에 사전에 선택해야만 합니다.

417
00:29:01,313 --> 00:29:05,623
데이터에서 직접적으로 배울 방법은 없습니다.

418
00:29:05,623 --> 00:29:10,260
그럼 다음 질문은 "실제로는 하이퍼 파라미터는 어떻게 정하는지" 
입니다.

419
00:29:10,260 --> 00:29:12,277
그리고 그건 매우 문제의존적(problem-dependent)입니다.

420
00:29:12,277 --> 00:29:17,957
대부분의 사람들이 하는 가장 단순한 방법은 바로  데이터에 맞게
다양한 하이퍼파라미터 값을 시도해 보는 것입니다.

421
00:29:17,957 --> 00:29:20,950
그리고 어떤것이 가장 좋은지를 알아내는 것입니다.

422
00:29:20,950 --> 00:29:22,404
질문 있습니까?

423
00:29:22,404 --> 00:29:26,071
[질문하는 학생]

424
00:29:29,589 --> 00:29:34,447
질문은 "어디에서 L1 Distance가 L2 Distance보다 
더 좋은지" 입니다.

425
00:29:34,447 --> 00:29:36,800
제 생각에 그것은 정말 문제 의존적이고,

426
00:29:36,800 --> 00:29:41,204
이 경우에는 L1을 쓰고 이 경우에는 L2를 써라 라고
말하기가 참 어렵습니다만

427
00:29:41,204 --> 00:29:50,185
L1은 좌표계에 의존적이기 때문에 
여러분의 데이터가 좌표계에 의존적인지가 관건이라 생각합니다.

428
00:29:50,185 --> 00:29:55,513
만약 어떤 특징 벡터가 있고, 이 벡터의 각 요소가 어떤 의미를
지니고 있다면

429
00:29:55,513 --> 00:29:58,583
예를들어 여러분이 어떤 이유가 되었든
직원들을 분류하고자 한다면

430
00:29:58,583 --> 00:30:03,976
그 벡터의 다양한 요소 각각이 직원들의 서로다른 특징들에 
영향을 미치게 됩니다.

431
00:30:03,976 --> 00:30:08,778
그 요소는 봉급이라던지 회사 근속년수와 
같은 것들이 될 수 있겠지요

432
00:30:08,778 --> 00:30:11,860
각각의 요소가 어떤 의미를 가지고 있다면,

433
00:30:11,860 --> 00:30:15,850
L1 을 사용하는것이 좀 더 괜찮을 지도 모릅니다.

434
00:30:15,850 --> 00:30:19,989
다시 돌아가서, 일반적으로는 하이퍼 파라미터가
전적으로 어떤 문제인지, 그리고 어떤 데이터인지에 의존적입니다.

435
00:30:19,989 --> 00:30:24,381
하이퍼 파라미터를 어떻게 정하느냐에 대한 가장 좋은 답은
그저 여러 시도를 해보고 더 좋은 것을 선택하는 것입니다.

436
00:30:28,381 --> 00:30:32,413
다양한 하이퍼 파라미터 값들을 실험해보고 최상의 값을
구하는것에 있어서도

437
00:30:32,413 --> 00:30:34,238
여기에도 다양한 선택사항이 있을 수 있습니다.

438
00:30:34,238 --> 00:30:38,268
"다양한 하이퍼 파라미터를 시도해 본다는 것" 과
"그중 최고를 선택하는 것" 이 무슨 뜻일까요?

439
00:30:38,268 --> 00:30:42,911
아마 처음 떠오르는 아이디어는 아주 심플하게 선택하는 것인데

440
00:30:42,911 --> 00:30:47,691
그것은 여러분들의 학습데이터의 정확도와 성능을 최고로 끌어 
올릴 수 있는 하이퍼 파라미터를 선택하는 것입니다.

441
00:30:47,691 --> 00:30:49,961
사실 이건 정말 끔찍한 생각입니다.

442
00:30:49,961 --> 00:30:52,137
절대 해서는 안됩니다.

443
00:30:52,137 --> 00:30:55,717
NN 분류기로 구체적인 예를 들어보자면

444
00:30:55,717 --> 00:31:00,157
만약 우리가 K = 1로 둔다면 학습 데이터를
아주 완벽하게 분류할 것입니다.

445
00:31:01,124 --> 00:31:04,420
그러니 그런 방법(트레이닝 데이터의 정확도를 올리는)를 쓴다면
항상 K = 1 을 선택할 것입니다.

446
00:31:04,420 --> 00:31:06,390
하지만 우리가 좀 전에 예제에서도 봤듯이

447
00:31:06,390 --> 00:31:10,446
실제로는 K를 더 큰 값을 두는 것이

448
00:31:10,446 --> 00:31:13,184
학습 데이터에서 몇개는 잘못 분류할 수는 있지만

449
00:31:13,184 --> 00:31:17,915
실제로 학습 데이터에 없던 데이터의 경우에서는
더 좋은 성능을 보일 수 있습니다.

450
00:31:17,915 --> 00:31:19,208
그리고 궁극적으로 기계학습에서는

451
00:31:19,208 --> 00:31:24,463
학습 데이터에 얼마나 잘 맞는지가 중요한 것이 아니라 
우리가 학습시킨 분류기가

452
00:31:24,463 --> 00:31:27,051
학습 후에 한번도 보지 못한 데이터를 얼마나 잘 예측하는지가
중요한 것입니다.

453
00:31:27,051 --> 00:31:30,495
그러므로 트레이닝 데이터만 보는것은 정말 최악입니다.
비추입니다.

454
00:31:30,495 --> 00:31:34,856
그럼 또 다른 아이디어가 있을 수 있습니다. 
전체 데이터 셋을 가져와서는

455
00:31:34,856 --> 00:31:38,390
트레이닝 데이터를 쪼개서 일부를 테스트 데이터로 사용하는 것입니다.

456
00:31:38,390 --> 00:31:44,409
그럼 이제 학습 데이터로 다양한 하이퍼파라미터 값들로
학습을 시키고

457
00:31:44,409 --> 00:31:49,584
테스트 데이터에 적용시켜본 다음에

458
00:31:49,584 --> 00:31:53,716
최고의 성능을 가진 하이퍼 파라미터를 선택할 것입니다.

459
00:31:54,582 --> 00:31:57,414
이건 좀 더 합리적인 전략같이 보이지만

460
00:31:57,414 --> 00:31:59,546
그러나 사실은, 이 방법 또한 아주 끔찍한 생각입니다.

461
00:31:59,546 --> 00:32:01,087
절대 하면 안됩니다.

462
00:32:01,087 --> 00:32:06,515
왜냐하면, 다시 기계학습 시스템의 요지로 돌아가보자면 
우리는 알고리즘이 어떻게 작동할 지를 알고싶은 것입니다.

463
00:32:06,515 --> 00:32:08,017
그러니 테스트셋의 목적은

464
00:32:08,017 --> 00:32:14,523
한번도 보지 못했던 야생의 데이터에 우리 알고리즘이
어떻게 동작할지를 측정하는 것입니다.

465
00:32:14,523 --> 00:32:19,749
만약 우리가 이 전략으로 여러 하이퍼파라미터로 학습시켜보고

466
00:32:19,749 --> 00:32:23,363
테스트 데이터에서 가장 성능이 좋은 것을 뽑아낸다면

467
00:32:23,363 --> 00:32:31,663
그러면 우리는 그저 "그 테스트 셋에서만" 잘 맞는 하이퍼 
파라미터를 고른 것일수도 있습니다.

468
00:32:31,663 --> 00:32:38,280
그러면 현재 이 테스트셋에서 보인 성능은 더이상
새로운, 한번도 보지못한 데이터의 성능을 대표할 수 없는 것입니다.

469
00:32:38,280 --> 00:32:41,491
그러니 이것 또한 하지 말아야 합니다.
안좋은 생각입니다.

470
00:32:41,491 --> 00:32:44,672
그렇게 하면 곤경에 빠질 것입니다.

471
00:32:44,672 --> 00:32:49,192
훨씬 더 일반적인 방법은 데이터를 세개로 나누는 것입니다.

472
00:32:50,185 --> 00:32:57,305
데이터의 거의 대부분은 트레이닝 셋으로 나누고, 일부는
밸리데이션 셋, 그리고 테스트 셋으로 나누는 것입니다.

473
00:32:57,305 --> 00:33:03,500
그리고 일반적으로 하는 일은 다양한 하이퍼파라미터를 이용해서
"트레이닝 셋" 으로 알고리즘을 학습시키고

474
00:33:03,500 --> 00:33:11,621
"벨리데이션 셋" 으로 검증을 하고 벨리데이션 셋에서
최고의 성능을 보이는 하이퍼 파라미터를 선택하는 것입니다.

475
00:33:11,621 --> 00:33:13,719
그리고 개발을 다 마친 후에

476
00:33:13,719 --> 00:33:16,627
디버깅도 다 마치고
모든 것을 다 마친 후에

477
00:33:16,627 --> 00:33:21,614
그리고 벨리데이션 셋에서 가장 좋은 성능을 보인
분류기를 가지고서는

478
00:33:21,614 --> 00:33:23,401
테스트 셋은 "딱 한번만" 수행하는 것입니다.

479
00:33:23,401 --> 00:33:27,139
그 마지막 수치가 여러분들의 논문에 들어갈 것이고
또 여러분들의 보고서에도 들어갈 것이고

480
00:33:27,139 --> 00:33:32,393
그 숫자가 여러분의 알고리즘이 한번도 보지 못한 데이터에
얼마나 잘 동작해 주는지를 실질적으로 말해주는 것입니다.

481
00:33:32,393 --> 00:33:38,847
그리고 실제로 벨리데이션 데이터와 테스트 데이터를
엄격하게 나눠놓는 것은 상당히 중요합니다.

482
00:33:38,847 --> 00:33:45,653
예를 한가지 들어보자면, 우리는 연구 논문을 작성할때 
테스트 셋을 거의 마지막 쯤에야 한번 사용합니다.

483
00:33:45,653 --> 00:33:54,159
저는 논문을 쓸때 마감 일주일 전 부터만 테스트 셋을
사용합니다.

484
00:33:54,159 --> 00:33:57,961
우리는 정직하게 연구를 수행했고 논문의 수치는 공정하게 
측정했다는 것을 보장하기 위해서죠

485
00:33:57,961 --> 00:34:00,102
사실 이것을 정말로 중요합니다.

486
00:34:00,102 --> 00:34:03,883
여러분은 여러분의 테스트 데이터를 잘 통해해야만 합니다.

487
00:34:06,468 --> 00:34:10,840
또다른 하이퍼 파라미터와 관련된 전략은 바로 
크로스 벨리데이션(교차 검증) 입니다.

488
00:34:10,840 --> 00:34:17,317
이 방법은 작은 데이터셋일때 많이 사용하는 방법이고
딥 러닝에서는 많이 사용하진 않습니다.

489
00:34:17,317 --> 00:34:20,201
이 아이디에에서는 우선 테스트 데이터는 정해놓고

490
00:34:20,201 --> 00:34:25,534
그 테스트 데이터셋은 아주 마지막에만 씁니다

491
00:34:25,534 --> 00:34:31,265
그리고 나머지 데이터는 트레이닝 부분, 벨리데이션 부분 
으로 딱 나눠 놓는 것이 아니라

492
00:34:31,266 --> 00:34:35,515
대신에 트레이닝 데이터를 여러 부분으로 나누는 것 입니다.

493
00:34:35,516 --> 00:34:41,415
이런 식으로 돌아가면서 어떤 부분이 벨리데이션 셋으로
지정할지를 선택하는 것입니다.

494
00:34:41,415 --> 00:34:45,498
이 예제에서 우리는
5-Fold Cross Validation을 사용하고 있습니다.

495
00:34:45,498 --> 00:34:49,984
처음 4개의 fold에서 하이퍼 파라미터를 학습시키고

496
00:34:49,985 --> 00:34:51,928
남은 한 fold에서 알고리즘을 평가합니다.

497
00:34:51,928 --> 00:34:55,712
그리고 1,2,3,5 fold에서 다시 학습시키고

498
00:34:55,712 --> 00:34:57,769
4 fold로 평가합니다.

499
00:34:57,769 --> 00:35:00,293
이것을 계속 순환하는 것입니다.

500
00:35:00,293 --> 00:35:01,765
이런식으로 하게 되면

501
00:35:01,765 --> 00:35:07,511
어떤 하이퍼 파라미터가 더 강인한지데 대한
훨씬 더 높은 확인을 가질 수 있습니다.

502
00:35:07,511 --> 00:35:09,714
이런 방식은 거의 표준이긴 하지만

503
00:35:09,714 --> 00:35:13,285
실제로 딥러닝에서는 큰 모델을 학습시킬 때

504
00:35:13,285 --> 00:35:18,652
학습 자체가 계산량이 많기 때문에
실제로는 잘 쓰지 않습니다.

505
00:35:18,652 --> 00:35:19,519
질문 있습니까?

506
00:35:19,519 --> 00:35:23,186
[질문하는 학생]

507
00:35:29,515 --> 00:35:32,634
질문을 좀 더 구체적으로 말하자면

508
00:35:32,634 --> 00:35:35,728
트레이닝 셋과 벨리데이션 셋의 차이가 무엇인가 입니다.

509
00:35:35,728 --> 00:35:39,895
k-NN에 대해 생각해보자면

510
00:35:41,060 --> 00:35:46,974
트레이닝 셋은 우리가 레이블을 기억하고 있는 이미지들 입니다.

511
00:35:46,974 --> 00:35:52,451
그러면 이미지를 분류하기 위해서 이미지를 트레이닝 데이터의
각각의 이미지들과 비교하게 될 것입니다.

512
00:35:52,451 --> 00:35:56,618
그리고 가장 트레이닝 셋에서 가장 근접한 
곳으로 레이블링 하게 되는 것입니다.

513
00:36:00,052 --> 00:36:03,184
알고리즘은 트레이닝 셋의 모든 것을 기억할 것입니다.

514
00:36:03,184 --> 00:36:08,062
그리고 이제는 벨리데이션 셋을 가져와서는
트레이닝 데이터와 비교합니다.

515
00:36:08,062 --> 00:36:16,815
그리고 이를 통해서 분류기를 벨리데이션 셋에 적용했을 때
얼마만큼의 정확도가 나오는지 확인합니다.

516
00:36:16,815 --> 00:36:19,919
이것이 바로 트레이닝 셋과 벨리데이션 셋의 차이점 입니다.

517
00:36:19,919 --> 00:36:24,207
알고리즘은 트레이닝 셋의 레이블을 볼 수 있고

518
00:36:24,207 --> 00:36:28,473
벨리데이션 셋의 경우에는 직접적으로 접근할 수 없는 것입니다.

519
00:36:28,473 --> 00:36:34,043
우리는 벨리데이션 셋의 레이블을 알고리즘이 얼마나 잘 동작하고
있는지를 확인할때만 사용합니다.

520
00:36:34,043 --> 00:36:34,907
질문 있으십니까?

521
00:36:34,907 --> 00:36:38,574
[질문하는 학생]

522
00:36:44,373 --> 00:36:52,941
질문은, 이게 테스트 셋으로 나눠놓건 아니건 
어떻게  테스트 셋이야생의 한번도 못본 데이터를 대표할 수 있는지 입니다.

523
00:36:52,941 --> 00:36:55,955
이것은 실제도 문제가 될 수 있습니다

524
00:36:55,955 --> 00:37:01,863
기본적인 통계학적 가정이 하나 있는데 여러분의 데이터는 독립적이며, 
유일한 하나의 분포에서 나온다는 것입니다 (i.i.d assumption)

525
00:37:01,863 --> 00:37:10,125
그러니 여러분들의 모든 데이터는 같은 
확률 분포에서 비롯되어야만 합니다.

526
00:37:10,125 --> 00:37:12,948
물론 실제로는 그런 항상 그런 경우는 없겠지만

527
00:37:12,948 --> 00:37:20,951
여러분은 분명히 테스트 셋이 야생의 데이터를 
엄청 잘 표현하지 못하는 경우를 경험하게 될 수 있습니다.

528
00:37:20,951 --> 00:37:25,473
그리고 이런 류의 문제는 datasets crators와
dataset curators가 생각해 볼 문제입니다.

529
00:37:25,473 --> 00:37:28,626
하지만, 예컨데 제가 데이터 셋을 만들때
하는 한가지 일은

530
00:37:28,626 --> 00:37:34,252
데이터를 수집하는 일관된 방법론을 가지고 
대량의 데이터를 한번에 수집하는 것입니다.

531
00:37:34,252 --> 00:37:38,690
그다음에 무작위로 트레이닝 데이터와 
테스트 데이터를 나누는 것입니다.

532
00:37:38,690 --> 00:37:43,024
한가지 여러분의 계획을 망칠 수 있는 것은 
데이터를 지속적으로 모으고 있는 경우

533
00:37:43,024 --> 00:37:46,343
먼저 수집한 데이터들을 트레이닝 데이터로 쓰고

534
00:37:46,343 --> 00:37:51,613
이후에 모은 데이터를 테스트 데이터로 사용한다면
문제를 이르킬 수 있는 변화가 생길 수 있습니다.

535
00:37:51,613 --> 00:37:55,831
하지만 여러분의 데이터셋 전체에서
무작위로 나눈다면

536
00:37:55,831 --> 00:37:59,762
그것이 바로 실제 그 문제를 완화 시킬 수 있는 방법이 될 것입니다.

537
00:38:04,297 --> 00:38:08,351
여러분이 크로스 벨리데이션 과정을
거치고 나면

538
00:38:08,351 --> 00:38:11,493
결국에는 여기 보이는것 과 같은 그래프를 
볼 수 있을 것입니다.

539
00:38:11,493 --> 00:38:17,354
여기 X 축에서는 K-NN 분류기의 K의 값을 나타냅니다.

540
00:38:17,354 --> 00:38:26,961
그리고 Y 축에서는 어떤 데이터 셋에 대해서
K 값 별 우리의 분류기의 정확도를 보여줍니다.

541
00:38:26,961 --> 00:38:31,705
이 경우에 5-fold cross vaildation 이 수행된 것을 
확인할 수 있으며

542
00:38:31,705 --> 00:38:38,346
각각의 K에 대해서, 5개의 서로 다른 데이터에 대해서 얼마나 
우리 알고리즘이 잘 동작하는지를 알려줍니다.

543
00:38:38,346 --> 00:38:41,050
그리고 다시 그 질문을 돌아가서

544
00:38:41,050 --> 00:38:44,748
테스트 셋을 가지는 것이 우리의 알고리즘에
좋은 영향을 미치는지 아닌지에 관해서라면

545
00:38:46,239 --> 00:38:50,276
K fold cross vaildation이 아마도 그 수치를
정량화 하는데 조금은 도움을 줄 것입니다.

546
00:38:50,276 --> 00:38:57,606
그리고 우리는 이 알고리즘이 다양한 validation folds에서 어떻게
성능을 내는지에 대한 분산(variance)을 확인해 볼 수 있습니다.

547
00:38:57,606 --> 00:39:04,301
분산을 보면 무엇이 최고인지 뿐만 아니라
그 성능에 대한 분포 또한 알 수 있습니다.

548
00:39:04,301 --> 00:39:06,442
그래서, 여러분이 기계학습 모델을 학습시키고 있다면

549
00:39:06,442 --> 00:39:08,151
결국 이런 식의 그래프를 그리게 될 것입니다.

550
00:39:08,151 --> 00:39:12,380
그리고 이 그래프는 정확도가 어떤지, 성능이 어떤지를
하이퍼 파라미터에 대한 함수로 나타내 줍니다.

551
00:39:12,380 --> 00:39:19,995
그리고 결국에는 벨리데이션 셋의 성능을 최고로 하는
모델 또는 하이퍼 파라미터를 선택하게 될 것입니다.

552
00:39:19,995 --> 00:39:25,528
이 예제에서는 아마 K = 7 일때가 가장 좋은
성능을 보이는 것을 알 수 있습니다.

553
00:39:29,713 --> 00:39:34,458
이미지에서는 k-NN 분류기를 실제로는 잘 쓰지 않습니다.

554
00:39:34,458 --> 00:39:38,233
왜냐하면 우리가 앞서 이야기한 문제들 때문입니다.

555
00:39:38,233 --> 00:39:41,393
첫번째 문제는 너무 느리다는 것입니다.

556
00:39:41,393 --> 00:39:44,287
우리가 원하는 것과 정 반대이며
이 내용은 앞서 이야기한 적이 있었습니다.

557
00:39:44,287 --> 00:39:54,495
또 하나의 문제는 Euclidean Distance나 L1 Distance와
같은 방법은 이미지간의 거리를 측정하기에 알맞지 않기 때문입니다.

558
00:39:54,495 --> 00:40:01,254
이러한 벡터간의 거리와 관련된 함수들은 
이미지들 간의 지각적유사성과는 잘 맞지 않습니다.

559
00:40:01,254 --> 00:40:04,076
여러분들 이미지간의 차이를 어떻게 지각하십니까?

560
00:40:04,076 --> 00:40:06,910
우리가 만든 이 예제를 보면

561
00:40:06,910 --> 00:40:08,796
왼쪽 그림에 한 여성이 있습니다.

562
00:40:08,796 --> 00:40:11,234
오른쪽에는 세 개의 왜곡된 이미지가 있습니다.

563
00:40:11,234 --> 00:40:18,416
눈과 입을 가려도 보고, 몇 픽셀식 이동도 시켜보고, 
전체 이미지에 파란색 색조도 추가시켜 보았습니다.

564
00:40:18,416 --> 00:40:22,785
그리고 박스친 이미지와 원본

565
00:40:22,785 --> 00:40:25,425
살짝 움직인 이미지와 원본, 그리고 색이 변한 이미지와 
원본의 사이의 Euclidean Distance를 비교해보면

566
00:40:25,425 --> 00:40:27,735
그들은 모두 동일한  L2 Distance를 가집니다.

567
00:40:27,735 --> 00:40:29,469
이것은 별로 좋지 않을것 같습니다.

568
00:40:29,469 --> 00:40:34,952
왜냐하면 L2 Distance가 이미지들 간의 어떤 
지각적인 Distance를 포착해 내는데

569
00:40:34,952 --> 00:40:39,119
별로 좋지 않다는 느낌을 주기 때문입니다.

570
00:40:40,642 --> 00:40:46,819
K-nn 분류기의 또 다른 문제 중 하나는 바로 우리가
"차원의 저주"라고 부르는 것입니다.

571
00:40:46,819 --> 00:40:51,279
그래서 우선 다시 K-NN 분류기도 돌아가 보자면

572
00:40:51,279 --> 00:40:57,186
K-NN이 하는 일은 각각의 트레이닝 데이터을 이용하여
각각의 공간을 나누는 일이였습니다.

573
00:40:57,186 --> 00:41:01,105
이것이 의미하는 바는 만약 우리가 k-NN 분류기가
잘 동작하기를 기대한다면

574
00:41:01,105 --> 00:41:05,646
우리는 그 공간을 상당히 조밀하게 커버할만한 
트레이닝 샘플들이 필요한 것입니다.

575
00:41:05,646 --> 00:41:15,004
그렇지 않으면 가장 가까운 이웃이 사실은 엄청 멀 수도 있고, 
그 가장 가까운 이웃은 테스트 이미지와 별로 유사하지 않을 것입니다.

576
00:41:16,738 --> 00:41:19,197
그리고 문제는 바로 실제로
공간을 조밀하게 덮어야 한다는 것은

577
00:41:19,197 --> 00:41:21,467
우리는  많은 량의 학습 데이터가 있어야 한다는 것을 의미하고

578
00:41:21,467 --> 00:41:24,666
이는 차원에 따라 기하급수 적으로 증가한다는 의미입니다.

579
00:41:24,666 --> 00:41:29,217
이것은 아주 좋지 않고, 기하급수적인 증가는 
기본적으로 항상 안좋습니다.

580
00:41:29,217 --> 00:41:35,587
여러분은 이런 고차원 공간에 존재하는 그 픽셀들의 공간을 조밀하게 
덮을 만큼의 충분한 이미지를 절대로 모으지 못할 것입니다.

581
00:41:35,587 --> 00:41:41,300
그래서 이 문제는 또 한가지의 k-NN을 사용하려 할때 여러분들이 
염두해야 할 점 이었습니다.

582
00:41:41,300 --> 00:41:45,701
그래서 요약을 해보자면, 우리는 이미지 분류 문제의
아이디어를 소개해 드리기 위해 k-NN을 이용하였습니다.

583
00:41:45,701 --> 00:41:51,445
우리는 이미지와 레이블을 가진 트레이닝 셋을 가졌고 
테스트 셋을 예측하는데 이용하였습니다.

584
00:41:51,445 --> 00:41:52,278
질문 있나요?

585
00:41:52,278 --> 00:41:54,519
[질문하는 학생]

586
00:41:54,519 --> 00:41:55,352
오 죄송합니다. 질문은

587
00:41:55,352 --> 00:41:57,271
"아까 그 그림이 어떤걸 의미하는지"

588
00:41:57,271 --> 00:41:59,168
"그림의 초록 점과 파란 점은 무엇인지" 였습니다.

589
00:41:59,168 --> 00:42:02,335
여기에는 우리가 트레이닝 샘플이 있는 것입니다.

590
00:42:03,463 --> 00:42:05,596
트레이닝 샘플을 각 점들로 표현합니다.

591
00:42:05,596 --> 00:42:11,004
그리고 각 점의 색은 트레이닝 샘플이 속한
카테고리를 나타낸다고 보시면 됩니다.

592
00:42:11,004 --> 00:42:12,629
따라서 맨 왼쪽의 1차원을 살펴보면

593
00:42:12,629 --> 00:42:17,525
이 공간을 조밀하게 덮으려면 트레이닝 샘플 4개면 충분합니다.

594
00:42:17,525 --> 00:42:19,478
하지만 2차원으로 옮겨가면

595
00:42:19,478 --> 00:42:25,529
이 공간을 다 덮으려면 16개의 트레이닝 샘플이 필요하고
1차원에서의 4배라는 것을 알 수 있습니다.

596
00:42:25,529 --> 00:42:28,767
그리고 우리가 3, 4, 5 와 같이 더
큰 차원을 고려해보면

597
00:42:28,767 --> 00:42:32,344
그 공간을 조밀하게 덮기 위해 필요한
트레이닝 샘플의 수는

598
00:42:32,344 --> 00:42:35,200
차원이 늘어남에 따라 기하급수적으로 증가하게 됩니다.

599
00:42:35,200 --> 00:42:37,601
그래서, 이것은 당신에게 감각을주는 종류입니다,
어쩌면 2 차원으로

600
00:42:37,601 --> 00:42:40,501
우리는 이런 종류의 재미있는
곡선 모양을 가질 수 있습니다.

601
00:42:40,501 --> 00:42:44,848
또는 당신은 라벨의 임의적 인 다양성을 가질 수 있습니다.

602
00:42:44,848 --> 00:42:47,641
다른 차원 공간에서.

603
00:42:47,641 --> 00:42:53,029
k-NN 알고리즘은 그러한 내재적인 manifolds를
가정하지 않기 때문에

604
00:42:53,029 --> 00:42:58,796
이 알고리즘이 올바르게 작동하게 하기 위한 유일한 방법은
그 공간을 조밀하게 덮을 만큼의 트레이닝 샘플을 가지는 것입니다.

605
00:43:01,741 --> 00:43:04,915
지금까지 k-NN에 대해 살펴보았으며

606
00:43:04,915 --> 00:43:11,214
여러분은 아마 첫 과제에서 이를 실제로 구현해보고
이미지들로 실험해 볼 기회가 있을 것입니다.

607
00:43:11,214 --> 00:43:16,059
그리고 남은 시간은 k-NN에 대한 질문을 좀 더 받고
다음 주제로 넘어 가도록 하겠습니다.

608
00:43:16,059 --> 00:43:16,892
질문있나요?

609
00:43:16,892 --> 00:43:21,014
[학생이 질문하고있다]

610
00:43:21,014 --> 00:43:22,034
죄송하지만 다시 말해주세요

611
00:43:22,034 --> 00:43:25,951
[학생이 질문하고있다]

612
00:43:28,437 --> 00:43:32,033
질문은 그러면 왜 저 이미지들이 같은 L2 Distance를
가지고 있는지 입니다.

613
00:43:32,033 --> 00:43:35,915
제 답변은, 제가 이 이미지들이 같은 L2 Distance를 가지도록
직접 심혀를 기울여 만들었기 떄문입니다.

614
00:43:35,915 --> 00:43:38,716
[웃음]

615
00:43:38,716 --> 00:43:45,096
저는 단지 L2 Distance가 이미지간의 유사도을 측정하는데는
좋지 않다는 것에 대한 느낌을 전달하고 싶었습니다.

616
00:43:45,096 --> 00:43:50,223
실제로 이 이미지들은 저마다 모두 다릅니다.

617
00:43:52,470 --> 00:43:57,649
하지만 여러분이 K-NN을 사용한다면 이미지 간의
유사도를 특정할 수 있는 유일한 방법은

618
00:43:57,649 --> 00:44:00,236
바로 이 단일 거리 성능 척도(L1/L2 등)을 이용하는 수 밖에 없습니다.

619
00:44:00,236 --> 00:44:05,229
그리고 이런 종류의 예는
해당 거리 측정 항목은 실제로 캡처하지 않습니다.

620
00:44:05,229 --> 00:44:08,949
거리 또는 차이에 대한 자세한 설명
이미지 간.

621
00:44:08,949 --> 00:44:15,384
그래서,이 경우에, 나는 단지 이것들을 조심스럽게 만들었습니다.
번역 및 이러한 오프셋을 정확히 일치시킵니다.

622
00:44:15,384 --> 00:44:16,217
문제?

623
00:44:16,217 --> 00:44:19,884
[질문하는 학생]

624
00:44:28,672 --> 00:44:29,925
그래서 문제는,

625
00:44:29,925 --> 00:44:31,249
아마 이것은 실제로 좋다.

626
00:44:31,249 --> 00:44:33,228
이 모든 것들 때문에

627
00:44:33,228 --> 00:44:36,615
실제로 이미지까지의 거리가 같습니다.

628
00:44:36,615 --> 00:44:38,024
이것은 아마도이 예에 해당 할 것입니다.

629
00:44:38,024 --> 00:44:40,390
하지만 저는 여러분이 예제를 만들 수 있다고 생각합니다.

630
00:44:40,390 --> 00:44:41,810
어쩌면 두 개의 원본 이미지가있을 수 있습니다.

631
00:44:41,810 --> 00:44:43,352
상자를 올바른 위치에 놓음으로써

632
00:44:43,352 --> 00:44:44,270
또는 그들을 착색,

633
00:44:44,270 --> 00:44:46,652
우리는 그것이 훨씬 더 가까워 질 수 있습니다.

634
00:44:46,652 --> 00:44:48,316
니가 원하는 무엇이라도, 그렇지?

635
00:44:48,316 --> 00:44:50,850
이 예에서 우리는 일종의 임의적 인 일을 할 수 있습니다.

636
00:44:50,850 --> 00:44:52,007
이동 및 착색

637
00:44:52,007 --> 00:44:54,612
이 거리를 거의 임의로 변화시키는 것

638
00:44:54,612 --> 00:44:57,469
이러한 이미지의 인식 적 특성을 변경하지 않고

639
00:44:57,469 --> 00:44:59,256
그래서,이게 실제로 너를 망칠 수 있다고 생각해.

640
00:44:59,256 --> 00:45:03,172
원본 이미지가 여러 개인 경우

641
00:45:03,172 --> 00:45:04,039
문제?

642
00:45:04,039 --> 00:45:07,956
[학생이 질문하고있다]

643
00:45:15,207 --> 00:45:16,040
질문은 ~이야,

644
00:45:16,040 --> 00:45:17,339
실제 사례에서 공통적인지 여부

645
00:45:17,339 --> 00:45:20,664
돌아가서 전체 데이터 세트를 재교육

646
00:45:20,664 --> 00:45:24,098
그 최고의 하이퍼 파라미터를 찾았습니까?

647
00:45:24,098 --> 00:45:27,765
그래서 사람들은 때로는 이것을 실제로 수행합니다.

648
00:45:28,787 --> 00:45:30,982
그러나 그것은 다소 맛이 있습니다.

649
00:45:30,982 --> 00:45:32,568
그 마감 기한을 정말로 서두르고 있다면

650
00:45:32,568 --> 00:45:34,430
그리고 당신은 정말로이 모델을 문 밖으로 나오게해야합니다.

651
00:45:34,430 --> 00:45:36,781
그런 다음 모델을 재 훈련하는 데 오랜 시간이 걸리면

652
00:45:36,781 --> 00:45:38,176
전체 데이터 세트에서,

653
00:45:38,176 --> 00:45:39,875
어쩌면 당신은 그것을하지 않을 것입니다.

654
00:45:39,875 --> 00:45:41,776
하지만 시간이 조금 있으면

655
00:45:41,776 --> 00:45:43,432
그리고 조금 더 여분의 계산,

656
00:45:43,432 --> 00:45:45,929
그리고 당신은 그 여분의 1 %

657
00:45:45,929 --> 00:45:50,012
성능면, 당신이 사용할 수있는 속임수입니다.

658
00:45:53,288 --> 00:45:54,858
그래서 우리는 k- 가장 가까운 이웃이

659
00:45:54,858 --> 00:45:56,758
좋은 속성이 많이 있습니다.

660
00:45:56,758 --> 00:45:58,409
기계 학습 알고리즘의

661
00:45:58,409 --> 00:46:00,490
그러나 실제로는 그렇게 크지는 않습니다.

662
00:46:00,490 --> 00:46:03,823
실제로 이미지에서 많이 사용되지 않습니다.

663
00:46:05,258 --> 00:46:07,134
그래서 내가 이야기하고 싶은 것은 다음과 같습니다.

664
00:46:07,134 --> 00:46:08,895
선형 분류.

665
00:46:08,895 --> 00:46:11,753
그리고 선형 분류는 다시 한번 아주 간단한 학습입니다

666
00:46:11,753 --> 00:46:14,981
알고리즘을 사용하지만 이것은 매우 중요해질 것입니다

667
00:46:14,981 --> 00:46:17,257
우리가 전체 신경 네트워크를 구축하도록 도와주세요.

668
00:46:17,257 --> 00:46:19,845
전체 컨벌루션 네트워크.

669
00:46:19,845 --> 00:46:21,736
그래서 한 비유 사람들이 자주 이야기합니다.

670
00:46:21,736 --> 00:46:23,470
신경망으로 작업 할 때

671
00:46:23,470 --> 00:46:26,242
우리는 그것들을 레고 블록과
같은 것으로 생각하고 있습니다.

672
00:46:26,242 --> 00:46:28,154
다른 종류의 구성 요소를 가질 수 있습니다.

673
00:46:28,154 --> 00:46:30,345
신경 네트워크 및 이러한 구성 요소 스틱 수 있습니다.

674
00:46:30,345 --> 00:46:33,814
이 큰 타워들을 함께 지어서

675
00:46:33,814 --> 00:46:36,378
컨벌루션 네트워크.

676
00:46:36,378 --> 00:46:38,404
우리가 볼 수있는 가장 기본적인 빌딩 블록 중 하나

677
00:46:38,404 --> 00:46:41,513
다양한 유형의 심층 학습 애플리케이션

678
00:46:41,513 --> 00:46:43,215
이 선형 분류 자입니다.

679
00:46:43,215 --> 00:46:44,996
그래서, 나는 그것이 실제로 정말로 중요하다고 생각합니다.

680
00:46:44,996 --> 00:46:46,905
무슨 일이 일어나고 있는지 잘 이해해야한다.

681
00:46:46,905 --> 00:46:48,270
선형 분류.

682
00:46:48,270 --> 00:46:50,236
이것들은 아주 잘 일반화 될 것이기 때문에

683
00:46:50,236 --> 00:46:52,712
전체 신경 네트워크에.

684
00:46:52,712 --> 00:46:55,243
이 모듈 적 성격의 또 다른 예가 있습니다.

685
00:46:55,243 --> 00:46:56,139
신경 네트워크

686
00:46:56,139 --> 00:46:58,728
이미지 캡션에 관한 우리 자신의
연구실에서의 일부 연구에서 나온 것이지만,

687
00:46:58,728 --> 00:47:00,281
약간의 미리보기처럼.

688
00:47:00,281 --> 00:47:02,847
여기서는 이미지를 입력하고 싶습니다.

689
00:47:02,847 --> 00:47:04,789
서술문을 출력한다.

690
00:47:04,789 --> 00:47:06,226
이미지를 설명합니다.

691
00:47:06,226 --> 00:47:08,162
그리고 이런 종류의 작품은

692
00:47:08,162 --> 00:47:10,710
우리는 하나의 길쌈 신경 네트워크를 찾고 있습니다.

693
00:47:10,710 --> 00:47:11,548
이미지에서,

694
00:47:11,548 --> 00:47:13,444
및 알고있는 반복적 인 신경망

695
00:47:13,444 --> 00:47:14,496
언어에 관해서.

696
00:47:14,496 --> 00:47:16,664
우리는이 두 조각을 함께 붙일 수 있습니다.

697
00:47:16,664 --> 00:47:18,776
레고 블록처럼 모든 것을 함께 훈련 시켜라.

698
00:47:18,776 --> 00:47:20,919
끝내주는 멋진 시스템

699
00:47:20,919 --> 00:47:22,767
그것은 사소한 일을 할 수 있습니다.

700
00:47:22,767 --> 00:47:25,077
그리고 우리는이 모델의 세부
사항을 통해 작업 할 것입니다.

701
00:47:25,077 --> 00:47:26,388
클래스에서 앞으로,

702
00:47:26,388 --> 00:47:27,711
그러나 이것은 당신에게 감각을줍니다.

703
00:47:27,711 --> 00:47:30,209
이러한 심층 신경 네트워크는 레고와 비슷합니다.

704
00:47:30,209 --> 00:47:31,999
및이 선형 분류기

705
00:47:31,999 --> 00:47:34,082
가장 기본적인 빌딩 블록과 비슷합니다.

706
00:47:34,082 --> 00:47:36,082
이 거대한 네트워크 중.

707
00:47:37,096 --> 00:47:39,189
그러나 그것은 강의 2에 대해 너무 흥미 롭습니다.

708
00:47:39,189 --> 00:47:41,257
그래서 우리는 잠시 CIFAR-10으로 돌아 가야합니다.

709
00:47:41,257 --> 00:47:42,375
[웃음]

710
00:47:42,375 --> 00:47:45,641
CIFAR-10에는 5 만 건의 교육 사례가 있으며,

711
00:47:45,641 --> 00:47:49,808
각 이미지는 32 x 32 픽셀과
3 개의 색상 채널입니다.

712
00:47:52,068 --> 00:47:53,963
선형 분류에서, 우리는 약간의

713
00:47:53,963 --> 00:47:56,696
k- 가장 가까운 이웃과는 다른 접근법을 사용한다.

714
00:47:56,696 --> 00:48:01,646
따라서 선형 분류기는 가장 간단한 예제 중 하나입니다.

715
00:48:01,646 --> 00:48:04,734
우리가 파라 메트릭 모델이라고 부르는 것의

716
00:48:04,734 --> 00:48:07,548
이제 우리의 파라 메트릭 모델은 실제로 두 개의 다른

717
00:48:07,548 --> 00:48:08,685
구성 요소.

718
00:48:08,685 --> 00:48:12,201
이 이미지는 아마도 왼쪽의 고양이를 잡을 것입니다.

719
00:48:12,201 --> 00:48:13,539
이,

720
00:48:13,539 --> 00:48:17,384
우리가 보통 입력 데이터를 위해 X로 쓰는 것,

721
00:48:17,384 --> 00:48:20,220
또한 일련의 매개 변수 또는 가중치,

722
00:48:20,220 --> 00:48:23,475
보통 W라고도하며 때로는 세타라고도하며,

723
00:48:23,475 --> 00:48:24,767
문헌에 따라.

724
00:48:24,767 --> 00:48:26,974
이제 우리는 몇 가지 기능을 적을 것입니다.

725
00:48:26,974 --> 00:48:30,780
이것은 데이터 X와 매개 변수 W를 모두 취하는데,

726
00:48:30,780 --> 00:48:34,180
이제 10 개의 숫자가 나옵니다.

727
00:48:34,180 --> 00:48:37,950
각 10 점에 해당하는 점수는 무엇입니까?

728
00:48:37,950 --> 00:48:39,991
CIFAR-10의 카테고리

729
00:48:39,991 --> 00:48:44,232
고양이의 더 큰 점수와 마찬가지로,

730
00:48:44,232 --> 00:48:48,583
그 입력 X가 고양이 일 확률이 더 높음을 나타냅니다.

731
00:48:48,583 --> 00:48:49,827
그리고 지금 질문 하나?

732
00:48:49,827 --> 00:48:53,494
[질문하는 학생]

733
00:48:55,380 --> 00:48:56,717
미안, 그걸 반복 할 수 있니?

734
00:48:56,717 --> 00:48:58,863
[질문하는 학생]

735
00:48:58,863 --> 00:49:01,524
오, 그래서 문제는 세 가지가 무엇입니까?

736
00:49:01,524 --> 00:49:04,986
이 예에서 3 개는 3 색에 해당합니다.

737
00:49:04,986 --> 00:49:06,943
채널, 빨간색, 녹색 및 파란색.

738
00:49:06,943 --> 00:49:08,469
우리는 일반적으로 컬러 이미지 작업을하기 때문에,

739
00:49:08,469 --> 00:49:12,636
당신이 버리고 싶지 않은 멋진 정보입니다.

740
00:49:15,323 --> 00:49:17,243
따라서, k- 최근 접 설정

741
00:49:17,243 --> 00:49:18,999
대신 매개 변수가 없으며,

742
00:49:18,999 --> 00:49:21,686
우리는 단지 전체 훈련 데이터를 계속 유지하고 있습니다.

743
00:49:21,686 --> 00:49:22,657
전체 훈련 세트,

744
00:49:22,657 --> 00:49:24,092
시험 시간에 사용하십시오.

745
00:49:24,092 --> 00:49:25,825
그러나 이제는 파라 메트릭 접근법에서,

746
00:49:25,825 --> 00:49:28,196
우리는 훈련 자료에 대한 우리의 지식을 요약하려고합니다

747
00:49:28,196 --> 00:49:31,105
그 모든 지식을이 매개 변수들에 집어 넣어 라.

748
00:49:31,105 --> 00:49:33,607
이제 테스트 시간에 더 이상 실제
테스트가 필요하지 않습니다.

749
00:49:33,607 --> 00:49:35,371
훈련 데이터, 우리는 그것을 버릴 수 있습니다.

750
00:49:35,371 --> 00:49:37,938
테스트 시간에 이러한 매개 변수 W 만 있으면됩니다.

751
00:49:37,938 --> 00:49:40,561
따라서 우리 모델의 효율성을 높일 수 있습니다.

752
00:49:40,561 --> 00:49:44,684
실제로 휴대폰과 같은 소형 장치에서 실행됩니다.

753
00:49:44,684 --> 00:49:47,277
그래서 일종의, 깊은 학습에 관한 전체 이야기

754
00:49:47,277 --> 00:49:49,404
이것에 맞는 구조가 생겨났다.

755
00:49:49,404 --> 00:49:50,906
기능, F.

756
00:49:50,906 --> 00:49:53,451
다른 기능적 양식을 적어 놓을 수 있습니다.

757
00:49:53,451 --> 00:49:55,406
서로 다른 가중치와 데이터를 결합하는 방법

758
00:49:55,406 --> 00:49:58,608
복잡한 방법, 그리고 이들은 서로 다른

759
00:49:58,608 --> 00:50:01,169
네트워크 아키텍처.

760
00:50:01,169 --> 00:50:02,489
그러나 가장 간단한 예제

761
00:50:02,489 --> 00:50:04,132
이 두 가지를 결합하는 것

762
00:50:04,132 --> 00:50:05,729
그냥, 아마, 그들을 번식하는 것입니다.

763
00:50:05,729 --> 00:50:08,833
그리고 이것은 선형 분류 자입니다.

764
00:50:08,833 --> 00:50:13,181
그래서 우리의 F of X, W는
W times X와 같습니다.

765
00:50:13,181 --> 00:50:15,770
아마 당신이 상상할 수있는 가장
단순한 방정식 일 것입니다.

766
00:50:15,770 --> 00:50:16,603
그래서 여기,

767
00:50:16,603 --> 00:50:18,921
만약 당신이 이런 것들의 치수를 풀 수 있다면,

768
00:50:18,921 --> 00:50:23,088
우리는 우리의 이미지가 32 x 32의
값을 가졌을 것이라고 생각합니다.

769
00:50:24,871 --> 00:50:28,207
그러면 우리는 그 가치들을 취하고 그
다음에 스트레칭을 할 것입니다.

770
00:50:28,207 --> 00:50:31,424
그들을 긴 열 벡터로 밖으로 내 보낸다.

771
00:50:31,424 --> 00:50:34,715
그 중 한 항목은 3,072입니다.

772
00:50:34,715 --> 00:50:38,632
이제 우리는 10 개의 학점으로 끝내기를 원합니다.

773
00:50:39,746 --> 00:50:41,742
이 이미지에 대해 10 개의 숫자로 끝내기를 원합니다.

774
00:50:41,742 --> 00:50:44,236
10 가지 범주 각각에 대해 점수를줍니다.

775
00:50:44,236 --> 00:50:46,279
이것은 우리 행렬 W가,

776
00:50:46,279 --> 00:50:49,032
3072 년까지 10 년이어야합니다.

777
00:50:49,032 --> 00:50:51,299
그래서이 두 가지를 곱하면

778
00:50:51,299 --> 00:50:53,243
우리는 하나의 열 벡터로 끝날 것입니다.

779
00:50:53,243 --> 00:50:57,086
10 점 만점에 10 점을주었습니다.

780
00:50:57,086 --> 00:51:00,317
또한 때로는 일반적으로 이것을 볼 수 있습니다.

781
00:51:00,317 --> 00:51:01,910
우리는 종종 편견 용어를 추가 할 것입니다.

782
00:51:01,910 --> 00:51:04,724
10 요소의 상수 벡터가 될 것입니다

783
00:51:04,724 --> 00:51:06,669
교육 자료와 상호 작용하지 않는

784
00:51:06,669 --> 00:51:09,656
대신에 우리에게 일종의 독립적 인 데이터를 제공합니다.

785
00:51:09,656 --> 00:51:12,235
다른 클래스에 대한 일부 클래스의 환경 설정.

786
00:51:12,235 --> 00:51:13,878
그래서 당신이 상상할 수도 있습니다
당신이 있다면 데이터 세트

787
00:51:13,878 --> 00:51:16,300
균형이 맞지 않고 개보다 고양이가 더 많았습니다.

788
00:51:16,300 --> 00:51:19,259
예를 들어, 대응하는 바이어스 요소

789
00:51:19,259 --> 00:51:23,553
고양이는 다른 고양이보다 높을 것입니다.

790
00:51:23,553 --> 00:51:25,445
그래서 당신이 그림에 대해 생각한다면

791
00:51:25,445 --> 00:51:27,778
이 기능이하는 일,

792
00:51:28,930 --> 00:51:31,483
이 그림에서는 왼쪽에 예제가 있습니다.

793
00:51:31,483 --> 00:51:35,729
2 x 2 이미지 만있는 단순 이미지의

794
00:51:35,729 --> 00:51:37,099
그래서 그것은 총 4 개의 픽셀을 가지고 있습니다.

795
00:51:37,099 --> 00:51:39,832
선형 분류기가 작동하는 방식

796
00:51:39,832 --> 00:51:42,273
이 두 이미지를 두 이미지로 찍는 것입니다.

797
00:51:42,273 --> 00:51:45,202
우리는 그것을 열 벡터로 뻗는다.

798
00:51:45,202 --> 00:51:46,577
네 가지 요소,

799
00:51:46,577 --> 00:51:49,301
이제이 예에서 우리는

800
00:51:49,301 --> 00:51:51,765
3 개의 종류, 고양이, 개 및 배,

801
00:51:51,765 --> 00:51:54,030
슬라이드에 10을 넣을 수 없기 때문에,

802
00:51:54,030 --> 00:51:58,197
이제 우리의 체중 행렬은 4에 3이 될 것입니다.

803
00:51:59,890 --> 00:52:02,236
그래서 우리는 4 개의 픽셀과 3 개의 클래스를가집니다.

804
00:52:02,236 --> 00:52:05,567
그리고 다시, 우리는 세 요소
바이어스 벡터를 가지고 있습니다.

805
00:52:05,567 --> 00:52:08,858
그것은 우리에게 데이터 독립 바이어스 조건을 제공합니다.

806
00:52:08,858 --> 00:52:11,125
각 카테고리에 대해.

807
00:52:11,125 --> 00:52:13,467
이제 우리는 고양이 점수가 들어가는 것을 보았습니다.

808
00:52:13,467 --> 00:52:16,717
이미지의 픽셀 사이의 제품

809
00:52:18,436 --> 00:52:20,650
이 행은 가중치 행렬에 있습니다.

810
00:52:20,650 --> 00:52:22,814
이 편견 용어와 함께 추가되었습니다.

811
00:52:22,814 --> 00:52:25,134
그래서, 당신이 그것을이 방법으로 볼 때

812
00:52:25,134 --> 00:52:28,146
선형 분류를 이해할 수 있습니다.

813
00:52:28,146 --> 00:52:30,157
거의 템플리트 매칭 방식입니다.

814
00:52:30,157 --> 00:52:32,444
이 행렬의 각 행

815
00:52:32,444 --> 00:52:35,652
이미지의 일부 템플리트에 해당합니다.

816
00:52:35,652 --> 00:52:38,113
이제 제품 또는 내 제품 입력

817
00:52:38,113 --> 00:52:41,099
행렬의 행과 열 사이

818
00:52:41,099 --> 00:52:43,183
이미지의 픽셀을 제공하고,

819
00:52:43,183 --> 00:52:45,165
이 점 제품 종류를 계산하면 우리에게 준다.

820
00:52:45,165 --> 00:52:47,874
클래스에 대한이 템플릿 간의 유사성

821
00:52:47,874 --> 00:52:50,458
및 우리의 심상의 화소.

822
00:52:50,458 --> 00:52:52,906
그리고 나서 바이어스가이 데이터를 제공합니다.

823
00:52:52,906 --> 00:52:57,073
각 클래스에 대한 독립 스케일링 오프셋.

824
00:53:00,837 --> 00:53:02,401
선형 분류를 생각하면

825
00:53:02,401 --> 00:53:04,705
이 템플릿 매칭의 관점에서

826
00:53:04,705 --> 00:53:07,532
우리는 실제로 그 무게 매트릭스의 행을 취할 수 있습니다.

827
00:53:07,532 --> 00:53:09,965
그들을 다시 이미지로 풀다.

828
00:53:09,965 --> 00:53:12,799
실제로 이러한 템플릿을 이미지로 시각화합니다.

829
00:53:12,799 --> 00:53:14,734
그리고 이것은 우리에게 어떤 선형의 어떤 감각을줍니다.

830
00:53:14,734 --> 00:53:16,769
분류 작업이 실제로 수행 중일 수 있습니다.

831
00:53:16,769 --> 00:53:18,908
우리의 데이터를 이해하려고 노력합니다.

832
00:53:18,908 --> 00:53:21,057
따라서이 예에서 우리는 앞서 나가고 훈련을 받았습니다.

833
00:53:21,057 --> 00:53:23,208
우리의 이미지에 선형 분류기.

834
00:53:23,208 --> 00:53:25,355
그리고 이제 바닥에 우리는 시각화하고 있습니다.

835
00:53:25,355 --> 00:53:28,974
학습 된 가중치 행렬에있는 행은 무엇입니까?

836
00:53:28,974 --> 00:53:30,892
10 개 범주 각각에 해당

837
00:53:30,892 --> 00:53:32,274
CIFAR-10에서.

838
00:53:32,274 --> 00:53:34,117
그리고 이런 방식으로 우리는

839
00:53:34,117 --> 00:53:35,686
이 심상에서 계속.

840
00:53:35,686 --> 00:53:38,841
예를 들어, 왼쪽, 왼쪽 하단,

841
00:53:38,841 --> 00:53:40,978
우리는 평면 클래스의 템플릿을 봅니다.

842
00:53:40,978 --> 00:53:42,941
이런 종류의 푸른 얼룩,

843
00:53:42,941 --> 00:53:44,856
중간에 이런 종류의 blobby

844
00:53:44,856 --> 00:53:46,739
그리고 아마 백그라운드에서 파란색,

845
00:53:46,739 --> 00:53:49,212
이 선형 분류기가

846
00:53:49,212 --> 00:53:51,574
비행기가 파란 물건을 찾고있는 것 같아.

847
00:53:51,574 --> 00:53:54,585
및 blobby 물건, 그리고 그 기능을 일으킬거야

848
00:53:54,585 --> 00:53:57,606
비행기를 더 좋아하는 분류 자.

849
00:53:57,606 --> 00:53:59,444
또는 우리가이 차보기를 보면,

850
00:53:59,444 --> 00:54:02,441
우리는 붉은 색 얼룩 무늬가있는 것을 보았습니다.

851
00:54:02,441 --> 00:54:04,801
상단에서 중간과 파란색 blobby 물건을 통해

852
00:54:04,801 --> 00:54:08,721
어쩌면 흐린 바람막이 일 수 있습니다.

853
00:54:08,721 --> 00:54:09,654
그러나 이것은 조금 이상합니다.

854
00:54:09,654 --> 00:54:11,271
이것은 실제로 차처럼 보이지 않습니다.

855
00:54:11,271 --> 00:54:13,716
어떤 개인의 차도 실제로 이처럼 보이지 않는다.

856
00:54:13,716 --> 00:54:15,628
그래서 문제는 선형 분류기

857
00:54:15,628 --> 00:54:18,317
각 클래스에 대해 하나의 템플릿 만 학습하고 있습니다.

858
00:54:18,317 --> 00:54:20,823
그래서 그 수업의 종류에 변화가 있다면

859
00:54:20,823 --> 00:54:21,748
나타날 수 있습니다.

860
00:54:21,748 --> 00:54:24,340
그 모든 다른 유사 콘텐츠를 평균화하려하고 있습니다.

861
00:54:24,340 --> 00:54:25,658
모든 다른 모습,

862
00:54:25,658 --> 00:54:27,461
하나의 단일 템플릿 만 사용하십시오.

863
00:54:27,461 --> 00:54:29,675
각 범주를 인식합니다.

864
00:54:29,675 --> 00:54:31,961
우리는 말에서 이것을 꽤 명백하게 볼 수 있습니다.

865
00:54:31,961 --> 00:54:33,139
분류 자.

866
00:54:33,139 --> 00:54:35,776
그래서 말 분류 자에서 우리는
바닥에 녹색 물건을 보았습니다.

867
00:54:35,776 --> 00:54:37,340
말은 보통 풀밭에 있기 때문입니다.

868
00:54:37,340 --> 00:54:39,289
그리고주의 깊게 보면 말은 실제로

869
00:54:39,289 --> 00:54:43,125
어쩌면 두 개의 머리, 각면에
머리가 하나있는 것 같습니다.

870
00:54:43,125 --> 00:54:45,855
그리고 저는 두 마리의 머리를
가진 말을 본 적이 없습니다.

871
00:54:45,855 --> 00:54:48,063
하지만 선형 분류기는 최선을 다하고 있습니다.

872
00:54:48,063 --> 00:54:50,513
그것은 오직 배울 수 있기 때문에 할 수 있습니다.

873
00:54:50,513 --> 00:54:52,788
카테고리 당 하나의 템플릿.

874
00:54:52,788 --> 00:54:55,085
그리고 우리가 신경 네트워크로 나아갈 때

875
00:54:55,085 --> 00:54:56,367
더 복잡한 모델,

876
00:54:56,367 --> 00:54:59,460
우리는 더 나은 정확도를 달성 할 수있을 것이다.

877
00:54:59,460 --> 00:55:01,230
그들은 더 이상이 제한이 없기 때문에

878
00:55:01,230 --> 00:55:05,230
카테고리 당 하나의 템플릿 만 학습하면됩니다.

879
00:55:09,030 --> 00:55:11,223
선형 분류기의 또 다른 관점

880
00:55:11,223 --> 00:55:13,523
이 이미지에 대한 생각으로 돌아가는 것입니다.

881
00:55:13,523 --> 00:55:15,649
포인트와 높은 차원 공간으로.

882
00:55:15,649 --> 00:55:19,232
그리고 각각의 이미지가

883
00:55:20,191 --> 00:55:23,328
이 고차원 공간의 한 점과 같습니다.

884
00:55:23,328 --> 00:55:26,341
이제 선형 분류기는

885
00:55:26,341 --> 00:55:29,305
선형 결정 경계선을 선형으로 그리려 함

886
00:55:29,305 --> 00:55:31,402
한 카테고리 간의 분리

887
00:55:31,402 --> 00:55:33,125
나머지 범주는

888
00:55:33,125 --> 00:55:35,838
어쩌면 왼쪽 상단에 올라있을 수도 있습니다.

889
00:55:35,838 --> 00:55:38,897
우리는 비행기의 훈련 예를 본다.

890
00:55:38,897 --> 00:55:41,446
훈련 과정 전반에 걸쳐

891
00:55:41,446 --> 00:55:43,845
선형 분류자가 가서 이것을 그리려고 할 것입니다.

892
00:55:43,845 --> 00:55:46,692
한 줄로 분리하는 파란색 선

893
00:55:46,692 --> 00:55:49,493
나머지 모든 클래스의 비행기 클래스.

894
00:55:49,493 --> 00:55:51,492
그리고 실제로는 재미있는 일입니다.

895
00:55:51,492 --> 00:55:53,902
이 과정은 무작위로 시작됩니다.

896
00:55:53,902 --> 00:55:55,818
가서 분리하여 분리하려고 시도하십시오.

897
00:55:55,818 --> 00:55:57,318
데이터를 올바르게.

898
00:55:58,709 --> 00:56:00,921
그러나 선형 분류에 대해 생각할 때

899
00:56:00,921 --> 00:56:04,000
이러한 방식으로,이 고차원 적 관점에서,

900
00:56:04,000 --> 00:56:06,768
당신은 몇 가지 문제가 무엇인지 다시 볼 수 있습니다.

901
00:56:06,768 --> 00:56:09,758
선형 분류가 생길 수도 있습니다.

902
00:56:09,758 --> 00:56:11,672
그리고 예제를 구성하는 것이 어렵지 않습니다.

903
00:56:11,672 --> 00:56:15,232
선형 분류기가 완전히 실패하는 데이터 세트를

904
00:56:15,232 --> 00:56:16,998
한 가지 예를 들면, 여기 왼쪽에,

905
00:56:16,998 --> 00:56:20,324
우리가 두 가지 범주의 데이터 집합을
가지고 있다고 가정 해 보겠습니다.

906
00:56:20,324 --> 00:56:22,067
그리고 이것들은 모두 다소 인공적 일 수 있습니다.

907
00:56:22,067 --> 00:56:24,990
하지만 아마도 우리의 데이터 세트에는 두 가지 범주가 있습니다.

908
00:56:24,990 --> 00:56:26,095
파란색과 빨간색.

909
00:56:26,095 --> 00:56:30,414
파란색 범주는 픽셀 수입니다.

910
00:56:30,414 --> 00:56:33,122
0보다 큰 이미지에서 홀수입니다.

911
00:56:33,122 --> 00:56:34,944
그리고 픽셀 수가 더 많은 곳에서는

912
00:56:34,944 --> 00:56:38,714
0보다 큽니다. 빨간색 카테고리로 분류하고 싶습니다.

913
00:56:38,714 --> 00:56:42,881
그래서 당신이 실제로 가서이 다른 것을 그린다면

914
00:56:43,991 --> 00:56:46,259
결정 영역은 비행기에서와 같이 보이지만,

915
00:56:46,259 --> 00:56:49,907
당신은 홀수 개의 픽셀을 가진 우리의
푸른 클래스를 볼 수 있습니다.

916
00:56:49,907 --> 00:56:53,426
비행기에서이 두 사분면이 될 것입니다.

917
00:56:53,426 --> 00:56:56,063
심지어 반대편 두 사분면이 될 것입니다.

918
00:56:56,063 --> 00:56:59,609
이제는 하나의 선형 선을 그릴 수있는 방법이 없습니다.

919
00:56:59,609 --> 00:57:01,364
파란색에서 빨간색을 분리합니다.

920
00:57:01,364 --> 00:57:03,412
그래서 이것은 선형 분류 자

921
00:57:03,412 --> 00:57:05,273
정말 어려울 것입니다.

922
00:57:05,273 --> 00:57:09,535
그리고 이것은 어쩌면 그런 인공적인
것이 아닐 수도 있습니다.

923
00:57:09,535 --> 00:57:10,912
화소를 계수하는 대신에,

924
00:57:10,912 --> 00:57:13,042
어쩌면 우리는 실제로 그 숫자가

925
00:57:13,042 --> 00:57:16,424
동물이나 사람의 이미지가 이상하거나 균등합니다.

926
00:57:16,424 --> 00:57:19,004
그래서 이런 종류의 패리티 문제

927
00:57:19,004 --> 00:57:21,145
확율로부터 확률을 분리하는 방법

928
00:57:21,145 --> 00:57:22,725
그 선형 분류

929
00:57:22,725 --> 00:57:25,725
전통적으로 정말로 투쟁합니다.

930
00:57:28,376 --> 00:57:31,438
선형 분류기가 실제로 어려움을 겪는 다른 상황

931
00:57:31,438 --> 00:57:33,974
multimodal 상황입니다.

932
00:57:33,974 --> 00:57:35,146
그래서 여기 오른쪽에,

933
00:57:35,146 --> 00:57:39,541
아마 우리의 파란 종류에는이 3 개의 다른 섬이 있습니다

934
00:57:39,541 --> 00:57:41,915
파란 종류가 사는 곳에,

935
00:57:41,915 --> 00:57:44,791
다른 모든 것은 다른 카테고리입니다.

936
00:57:44,791 --> 00:57:46,529
그래서, 말과 같은 것을 위해,

937
00:57:46,529 --> 00:57:47,961
우리는 앞의 예를 보았습니다.

938
00:57:47,961 --> 00:57:50,106
이것이 실제로 일어날 수있는 무언가입니다.

939
00:57:50,106 --> 00:57:50,959
실제로.

940
00:57:50,959 --> 00:57:53,560
픽셀 공간에 하나의 섬이있는 곳

941
00:57:53,560 --> 00:57:55,159
왼쪽을 보면서 말,

942
00:57:55,159 --> 00:57:57,268
그리고 오른쪽으로 보이는 또 다른 말 섬.

943
00:57:57,268 --> 00:58:00,360
이제는 단일 선형을 그리는 좋은 방법이 없습니다.

944
00:58:00,360 --> 00:58:03,757
이 두 분리 된 섬 사이의 경계.

945
00:58:03,757 --> 00:58:07,257
멀티 모달 데이터가있는 곳이라면 언제든지

946
00:58:08,098 --> 00:58:08,931
한 반처럼

947
00:58:08,931 --> 00:58:10,854
우주의 다른 지역에서 나타날 수있는

948
00:58:10,854 --> 00:58:13,963
선형 분류가 어려울 수도있는 또 다른 장소입니다.

949
00:58:13,963 --> 00:58:15,932
그래서 여러 가지 문제가 있습니다.

950
00:58:15,932 --> 00:58:18,575
선형 분류 자 (linear classifier)이지만,
그것은 매우 간단한 알고리즘이며,

951
00:58:18,575 --> 00:58:22,259
슈퍼 멋지고 해석하기 쉽고 이해하기 쉽습니다.

952
00:58:22,259 --> 00:58:24,412
그래서 당신은 실제로 이런 것들을 구현할 것입니다.

953
00:58:24,412 --> 00:58:27,245
너의 첫번째 숙제에.

954
00:58:28,852 --> 00:58:29,971
이 지점에서,

955
00:58:29,971 --> 00:58:30,980
우리는 얼마간 얘기했다.

956
00:58:30,980 --> 00:58:33,313
기능적 형태는 무엇입니까?

957
00:58:33,313 --> 00:58:34,402
선형 분류 자.

958
00:58:34,402 --> 00:58:36,711
그리고 우리는이 기능적 형태가

959
00:58:36,711 --> 00:58:39,185
행렬 벡터 곱셈의

960
00:58:39,185 --> 00:58:41,541
이 템플릿 매칭 개념에 해당함

961
00:58:41,541 --> 00:58:43,364
각 카테고리에 대한 단일 템플릿 학습

962
00:58:43,364 --> 00:58:44,922
귀하의 데이터에.

963
00:58:44,922 --> 00:58:48,339
그리고 일단 우리가이 훈련 된 행렬을 가지면

964
00:58:49,485 --> 00:58:52,499
당신은 실제로 가서 점수를 얻는데 사용할 수 있습니다.

965
00:58:52,499 --> 00:58:55,738
어떤 새로운 훈련 예도.

966
00:58:55,738 --> 00:58:58,104
하지만 우리가 당신에게 말하지 않은 것은

967
00:58:58,104 --> 00:59:00,597
당신은 실제로 올바른 W를 선택하는
방법에 대해 실제로 어떻게 생각합니까?

968
00:59:00,597 --> 00:59:01,951
귀하의 데이터 세트.

969
00:59:01,951 --> 00:59:03,908
우리는 방금 기능적인 형태가
무엇인지에 대해 이야기했습니다.

970
00:59:03,908 --> 00:59:06,907
그리고이 일에 무슨 일이 일어나고 있는지.

971
00:59:06,907 --> 00:59:11,086
그래서 우리는 다음 번에 정말로 집중할 것입니다.

972
00:59:11,086 --> 00:59:12,933
그리고 우리가 이야기 할 다음 강의

973
00:59:12,933 --> 00:59:14,668
전략과 알고리즘은 무엇인가?

974
00:59:14,668 --> 00:59:16,581
오른쪽 W를 선택하십시오.

975
00:59:16,581 --> 00:59:17,708
그리고 이것은 우리를 질문으로 이끌 것입니다.

976
00:59:17,708 --> 00:59:19,544
손실 함수 및 최적화

977
00:59:19,544 --> 00:59:21,322
결국 ConvNets.

978
00:59:21,322 --> 00:59:25,044
그래서, 다음주에 미리보기가 약간 있습니다.

979
00:59:25,044 --> 00:00:00,000
그게 오늘 우리가 가진 전부입니다.

